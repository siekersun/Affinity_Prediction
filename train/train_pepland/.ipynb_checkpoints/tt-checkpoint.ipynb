{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb111baf-d67c-4da5-9837-22779dcc610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KYPPYEPH' 'WSAVHSHD' 'LRWLIEELR' 'APYVQAFDS' 'TISYTYTY']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "train_csv_path = '/nas1/develop/lixiang/data/split_train_test/train_data.csv'\n",
    "valid_csv_path = '/nas1/develop/lixiang/data/split_train_test/test_data_numW1.csv'\n",
    "test_csv_path = '/nas1/develop/lixiang/data/split_train_test/test_data_numW2.csv'\n",
    "smiles_fp = '/nas1/develop/lixiang/data/class_AA/seq_smiles_fp_matrix.npz'\n",
    "smiles_H = '/nas1/develop/lixiang/data/class_AA/smiles_embed.h5'\n",
    "pepland_path = '/nas1/develop/lixiang/data/class_AA/ChemBERT_embed.h5'\n",
    "with h5py.File(smiles_H, \"r\") as f:\n",
    "    H = f[\"fp\"][:]\n",
    "\n",
    "data = np.load(smiles_fp)\n",
    "smiles=data['X']\n",
    "seqs_smiles=data['seq_ids']\n",
    "data.close()\n",
    "\n",
    "with h5py.File(pepland_path, \"r\") as f:\n",
    "    seqs_pepland = f[\"seq\"][:].astype(str)\n",
    "    pepland = f[\"embed\"][:]\n",
    "print(seqs_smiles[:5])\n",
    "# sequence → index\n",
    "seq_to_idx = {s: i for i, s in enumerate(seqs_smiles)}\n",
    "\n",
    "# sanity check\n",
    "assert (seqs_smiles == seqs_pepland).all(), \"Sequences mismatch in h5 files!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6b3730-d329-4699-bb49-95397bc8ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(train_csv_path)[:5000]\n",
    "\n",
    "train_seq_ids = train_df[\"PepetideID\"].tolist()\n",
    "train_y = train_df.iloc[:, 1].astype(\"float32\").values.reshape(-1, 1)\n",
    "train_y = np.log10(train_y)\n",
    "train_smiles = smiles[[seq_to_idx[s] for s in train_seq_ids]]\n",
    "train_H = H[[seq_to_idx[s] for s in train_seq_ids]]\n",
    "train_x = pepland[[seq_to_idx[s] for s in train_seq_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad041c15-1428-4593-9dd1-1cb82128ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_csv_path)[:5000]\n",
    "\n",
    "test_seq_ids = test_df[\"PepetideID\"].tolist()\n",
    "test_y = test_df.iloc[:, 1].astype(\"float32\").values.reshape(-1, 1)\n",
    "test_y = np.log10(test_y)\n",
    "test_smiles = smiles[[seq_to_idx[s] for s in test_seq_ids]]\n",
    "test_H = H[[seq_to_idx[s] for s in test_seq_ids]]\n",
    "test_x = pepland[[seq_to_idx[s] for s in test_seq_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc23d9b-04eb-476d-be00-afa337ba0b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 768]) torch.Size([10000, 1]) torch.Size([10000, 253]) torch.Size([10000, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X = torch.tensor(np.concatenate([train_x, test_x], 0), dtype=torch.float32)\n",
    "Y = torch.tensor(np.concatenate([train_y, test_y], 0), dtype=torch.float32)\n",
    "smiles = torch.tensor(np.concatenate([train_smiles, test_smiles], 0), dtype=torch.float32)\n",
    "H = torch.tensor(np.concatenate([train_H, test_H], 0), dtype=torch.float32)\n",
    "print(X.size(), Y.size(), smiles.size(), H.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "037786ce-0489-4b96-9958-4da83f346535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class smilesypergraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    原始超图卷积层（Zhou 2007）\n",
    "    X' = Dv^{-1/2} smiles W De^{-1} smiles^T Dv^{-1/2} X Theta\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_feats, out_feats, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.theta = nn.Linear(in_feats, out_feats, bias=use_bias)\n",
    "        self.act = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_normalization(smiles, W=None):\n",
    "        \"\"\"\n",
    "        构建归一化系数:\n",
    "        smiles: (N, E)\n",
    "        W: (E,) 超边权重，可为空\n",
    "        \"\"\"\n",
    "        N, E = smiles.shape\n",
    "        device = smiles.device\n",
    "        dtype = smiles.dtype\n",
    "\n",
    "        # 默认所有超边权重为 1\n",
    "        if W is None:\n",
    "            W = torch.ones(E, dtype=dtype, device=device)\n",
    "        else:\n",
    "            W = W.to(device).to(dtype).reshape(E)\n",
    "\n",
    "        # De：超边度，每条超边包含多少节点\n",
    "        De = smiles.sum(dim=0)  # (E,)\n",
    "        De_inv = torch.zeros_like(De)\n",
    "        mask_e = De > 0\n",
    "        De_inv[mask_e] = 1.0 / De[mask_e]\n",
    "\n",
    "        # Dv：节点度\n",
    "        Dv = (smiles * W.unsqueeze(0)).sum(dim=1)  # (N,)\n",
    "        Dv_inv_sqrt = torch.zeros_like(Dv)\n",
    "        mask_v = Dv > 0\n",
    "        Dv_inv_sqrt[mask_v] = 1.0 / torch.sqrt(Dv[mask_v])\n",
    "\n",
    "        return W, De_inv, Dv_inv_sqrt\n",
    "\n",
    "    def forward(self, X, smiles, W=None):\n",
    "        \"\"\"\n",
    "        X: (N, F_in)\n",
    "        smiles: (N, E)\n",
    "        W: (E,)\n",
    "        return: (N, F_out)\n",
    "        \"\"\"\n",
    "        # 计算归一化\n",
    "        W_vec, De_inv, Dv_inv_sqrt = self.build_normalization(smiles, W)\n",
    "\n",
    "        # 线性变换 X Θ\n",
    "        X_theta = self.theta(X)  # (N, F_out)\n",
    "\n",
    "        # Dv^{-1/2} X Θ\n",
    "        X_hat = Dv_inv_sqrt.unsqueeze(1) * X_theta\n",
    "\n",
    "        # smiles^T * (Dv^{-1/2} X Θ)\n",
    "        smilestX = smiles.T @ X_hat  # (E, F_out)\n",
    "\n",
    "        # W * De^{-1}\n",
    "        edge_scale = (W_vec * De_inv).unsqueeze(1)  # (E, 1)\n",
    "\n",
    "        # scale edges\n",
    "        smilestX = edge_scale * smilestX  # (E, F_out)\n",
    "\n",
    "        # smiles * (...)\n",
    "        out = smiles @ smilestX  # (N, F_out)\n",
    "\n",
    "        # final left normalize: Dv^{-1/2}\n",
    "        out = Dv_inv_sqrt.unsqueeze(1) * out\n",
    "\n",
    "        out = self.act(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6339b0e0-7507-4342-92a9-8dd9bab8c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class smilesGNNLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, out_dim, layer_num = 2):\n",
    "        super(smilesGNNLayer, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.conv = nn.ModuleList()\n",
    "        for _ in range(layer_num-1):\n",
    "            self.conv.append(smilesypergraphConv(embed_dim, embed_dim))\n",
    "        self.res = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W = nn.Parameter(torch.ones(1024))\n",
    "\n",
    "    def forward(self, x, smiles):\n",
    "        resx = x\n",
    "        for i in range(self.layer_num-1):\n",
    "            x = self.conv[i](x, smiles, self.W)\n",
    "        x = self.res(resx) + x\n",
    "        return x\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dp=0.5):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dp),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dp),\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dp),\n",
    "        )\n",
    "        self.resfc = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)+ self.resfc(x)\n",
    "# =========================\n",
    "# 3️⃣ 模型定义\n",
    "# =========================\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim=256, nhead=8, nfc=1, nlayers=3, dp=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nlayers = nlayers\n",
    "        self.nfc = nfc\n",
    "        self.x_fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 1*hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.x_encoder = nn.ModuleList()\n",
    "        for _ in range(self.nfc):\n",
    "            self.x_encoder.append(FCLayer(1*hidden_dim, 1*hidden_dim, dp=dp))\n",
    "        \n",
    "        self.smiles_encoder = nn.ModuleList()\n",
    "        for _ in range(self.nfc):\n",
    "            self.smiles_encoder.append(FCLayer(1*hidden_dim, 1*hidden_dim, dp=dp))\n",
    "\n",
    "        self.hgnn_encoder = nn.ModuleList()\n",
    "        self.hgnn_encoder\n",
    "        for _ in range(nlayers):\n",
    "            # self.hgnn_encoder.append(smilesGNNLayer(2*hidden_dim, 2*hidden_dim, layer_num=nlayers))\n",
    "            self.hgnn_encoder.append(smilesypergraphConv(embed_dim, embed_dim))\n",
    "        \n",
    "        self.res_fc1 = nn.Linear(253+emb_dim, 2*hidden_dim)\n",
    "        self.res_fc2 = nn.Linear(2*hidden_dim, 2*hidden_dim)\n",
    "        self.smiles_fc = nn.Sequential(\n",
    "            nn.Linear(253, 1*hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.norm_x = nn.LayerNorm(emb_dim)\n",
    "        self.norm_smiles = nn.LayerNorm(253)\n",
    "\n",
    "        # 预测层\n",
    "        self.predict = nn.Linear(2*hidden_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, smiles_x, H ): \n",
    "        \n",
    "        # smiles = smiles_x\n",
    "        smiles = H\n",
    "        # smiles_x = H\n",
    "\n",
    "        # smiles_x = self.norm_smiles(smiles_x)\n",
    "        # x = self.norm_x(x)\n",
    "        # smiles_emb = self.smiles_fc(smiles_x)\n",
    "\n",
    "        # x_emb = self.x_fc(x)\n",
    "\n",
    "        # for i in range(self.nfc):\n",
    "        #     x_emb = self.x_encoder[i](x_emb)\n",
    "        #     smiles_emb = self.smiles_encoder[i](smiles_emb)\n",
    "\n",
    "        # all_x = torch.concat([x_emb, smiles_emb], dim=-1)\n",
    "        all_x = torch.concat([x, smiles_x], dim=-1)\n",
    "        \n",
    "        all_res = all_x\n",
    "        for i in range(self.nlayers):\n",
    "            all_x = self.hgnn_encoder[i](all_x, smiles)\n",
    "            \n",
    "        all_x = self.res_fc2(all_res) + all_x\n",
    "        # 预测\n",
    "        y = self.predict(all_x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d5e4057-c30a-42c4-b5d4-fc6cabd66d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/800\n",
      "Train Loss: 14.9740 | Valid Loss: 14.4355\n",
      "⭐ Saved best model at epoch 1, val loss = 14.4355\n",
      "\n",
      "Epoch 2/800\n",
      "Train Loss: 4434.0225 | Valid Loss: 4577.7656\n",
      "\n",
      "Epoch 3/800\n",
      "Train Loss: 6290.2559 | Valid Loss: 7352.1260\n",
      "\n",
      "Epoch 4/800\n",
      "Train Loss: 50771.3828 | Valid Loss: 56274.5664\n",
      "\n",
      "Epoch 5/800\n",
      "Train Loss: 48.1384 | Valid Loss: 42.9993\n",
      "\n",
      "Epoch 6/800\n",
      "Train Loss: 289.6404 | Valid Loss: 351.9409\n",
      "\n",
      "Epoch 7/800\n",
      "Train Loss: 151.7419 | Valid Loss: 184.0402\n",
      "\n",
      "Epoch 8/800\n",
      "Train Loss: 27.9992 | Valid Loss: 34.6093\n",
      "\n",
      "Epoch 9/800\n",
      "Train Loss: 73.3527 | Valid Loss: 85.5213\n",
      "\n",
      "Epoch 10/800\n",
      "Train Loss: 199.5473 | Valid Loss: 227.3542\n",
      "\n",
      "Epoch 11/800\n",
      "Train Loss: 42.5879 | Valid Loss: 50.3071\n",
      "\n",
      "Epoch 12/800\n",
      "Train Loss: 7.8801 | Valid Loss: 8.6119\n",
      "⭐ Saved best model at epoch 12, val loss = 8.6119\n",
      "\n",
      "Epoch 13/800\n",
      "Train Loss: 20.3450 | Valid Loss: 21.3713\n",
      "\n",
      "Epoch 14/800\n",
      "Train Loss: 19.8113 | Valid Loss: 23.1580\n",
      "\n",
      "Epoch 15/800\n",
      "Train Loss: 55.6197 | Valid Loss: 67.4285\n",
      "\n",
      "Epoch 16/800\n",
      "Train Loss: 52.3870 | Valid Loss: 54.4514\n",
      "\n",
      "Epoch 17/800\n",
      "Train Loss: 39.4884 | Valid Loss: 43.8500\n",
      "\n",
      "Epoch 18/800\n",
      "Train Loss: 66.0966 | Valid Loss: 82.1383\n",
      "\n",
      "Epoch 19/800\n",
      "Train Loss: 46.7842 | Valid Loss: 53.9989\n",
      "\n",
      "Epoch 20/800\n",
      "Train Loss: 75.8792 | Valid Loss: 77.8467\n",
      "\n",
      "Epoch 21/800\n",
      "Train Loss: 57.9415 | Valid Loss: 66.4394\n",
      "\n",
      "Epoch 22/800\n",
      "Train Loss: 82.6425 | Valid Loss: 101.6889\n",
      "\n",
      "Epoch 23/800\n",
      "Train Loss: 80.6353 | Valid Loss: 84.4541\n",
      "\n",
      "Epoch 24/800\n",
      "Train Loss: 72.2375 | Valid Loss: 74.1450\n",
      "\n",
      "Epoch 25/800\n",
      "Train Loss: 92.0868 | Valid Loss: 114.7897\n",
      "\n",
      "Epoch 26/800\n",
      "Train Loss: 74.2016 | Valid Loss: 82.8254\n",
      "\n",
      "Epoch 27/800\n",
      "Train Loss: 66.7230 | Valid Loss: 73.1699\n",
      "\n",
      "Epoch 28/800\n",
      "Train Loss: 82.1268 | Valid Loss: 95.9108\n",
      "\n",
      "Epoch 29/800\n",
      "Train Loss: 75.0681 | Valid Loss: 76.0190\n",
      "\n",
      "Epoch 30/800\n",
      "Train Loss: 58.0386 | Valid Loss: 67.5531\n",
      "\n",
      "Epoch 31/800\n",
      "Train Loss: 66.3280 | Valid Loss: 86.5791\n",
      "\n",
      "Epoch 32/800\n",
      "Train Loss: 62.7717 | Valid Loss: 64.2995\n",
      "\n",
      "Epoch 33/800\n",
      "Train Loss: 49.8282 | Valid Loss: 58.4616\n",
      "\n",
      "Epoch 34/800\n",
      "Train Loss: 57.2651 | Valid Loss: 75.3373\n",
      "\n",
      "Epoch 35/800\n",
      "Train Loss: 49.9817 | Valid Loss: 52.9032\n",
      "\n",
      "Epoch 36/800\n",
      "Train Loss: 43.7078 | Valid Loss: 49.4548\n",
      "\n",
      "Epoch 37/800\n",
      "Train Loss: 47.2732 | Valid Loss: 64.3800\n",
      "\n",
      "Epoch 38/800\n",
      "Train Loss: 56.0393 | Valid Loss: 53.0437\n",
      "\n",
      "Epoch 39/800\n",
      "Train Loss: 39.7780 | Valid Loss: 48.1208\n",
      "\n",
      "Epoch 40/800\n",
      "Train Loss: 38.3814 | Valid Loss: 45.9922\n",
      "\n",
      "Epoch 41/800\n",
      "Train Loss: 42.5464 | Valid Loss: 41.3167\n",
      "\n",
      "Epoch 42/800\n",
      "Train Loss: 32.0294 | Valid Loss: 38.7056\n",
      "\n",
      "Epoch 43/800\n",
      "Train Loss: 36.4895 | Valid Loss: 49.0779\n",
      "\n",
      "Epoch 44/800\n",
      "Train Loss: 32.5320 | Valid Loss: 35.4751\n",
      "\n",
      "Epoch 45/800\n",
      "Train Loss: 29.7141 | Valid Loss: 32.7967\n",
      "\n",
      "Epoch 46/800\n",
      "Train Loss: 29.5071 | Valid Loss: 36.9772\n",
      "\n",
      "Epoch 47/800\n",
      "Train Loss: 26.1842 | Valid Loss: 31.8522\n",
      "\n",
      "Epoch 48/800\n",
      "Train Loss: 25.6011 | Valid Loss: 27.3627\n",
      "\n",
      "Epoch 49/800\n",
      "Train Loss: 22.9641 | Valid Loss: 28.1002\n",
      "\n",
      "Epoch 50/800\n",
      "Train Loss: 22.8298 | Valid Loss: 28.0440\n",
      "\n",
      "Epoch 51/800\n",
      "Train Loss: 22.2740 | Valid Loss: 25.4337\n",
      "\n",
      "Epoch 52/800\n",
      "Train Loss: 19.7950 | Valid Loss: 24.2591\n",
      "\n",
      "Epoch 53/800\n",
      "Train Loss: 20.1153 | Valid Loss: 26.8659\n",
      "\n",
      "Epoch 54/800\n",
      "Train Loss: 20.3300 | Valid Loss: 21.1625\n",
      "\n",
      "Epoch 55/800\n",
      "Train Loss: 17.9150 | Valid Loss: 22.1835\n",
      "\n",
      "Epoch 56/800\n",
      "Train Loss: 17.8650 | Valid Loss: 23.5497\n",
      "\n",
      "Epoch 57/800\n",
      "Train Loss: 16.8422 | Valid Loss: 18.6450\n",
      "\n",
      "Epoch 58/800\n",
      "Train Loss: 15.9858 | Valid Loss: 19.2711\n",
      "\n",
      "Epoch 59/800\n",
      "Train Loss: 17.2797 | Valid Loss: 24.3728\n",
      "\n",
      "Epoch 60/800\n",
      "Train Loss: 20.6953 | Valid Loss: 18.3558\n",
      "\n",
      "Epoch 61/800\n",
      "Train Loss: 14.4772 | Valid Loss: 16.0853\n",
      "\n",
      "Epoch 62/800\n",
      "Train Loss: 19.0110 | Valid Loss: 26.6641\n",
      "\n",
      "Epoch 63/800\n",
      "Train Loss: 13.2776 | Valid Loss: 15.0995\n",
      "\n",
      "Epoch 64/800\n",
      "Train Loss: 15.8108 | Valid Loss: 15.4000\n",
      "\n",
      "Epoch 65/800\n",
      "Train Loss: 13.2328 | Valid Loss: 17.7843\n",
      "\n",
      "Epoch 66/800\n",
      "Train Loss: 14.5930 | Valid Loss: 22.2497\n",
      "\n",
      "Epoch 67/800\n",
      "Train Loss: 12.0546 | Valid Loss: 13.7624\n",
      "\n",
      "Epoch 68/800\n",
      "Train Loss: 13.3573 | Valid Loss: 12.9024\n",
      "\n",
      "Epoch 69/800\n",
      "Train Loss: 11.3127 | Valid Loss: 13.7200\n",
      "\n",
      "Epoch 70/800\n",
      "Train Loss: 12.8394 | Valid Loss: 19.2077\n",
      "\n",
      "Epoch 71/800\n",
      "Train Loss: 10.0003 | Valid Loss: 12.4482\n",
      "\n",
      "Epoch 72/800\n",
      "Train Loss: 12.6053 | Valid Loss: 11.8261\n",
      "\n",
      "Epoch 73/800\n",
      "Train Loss: 9.5771 | Valid Loss: 12.3683\n",
      "\n",
      "Epoch 74/800\n",
      "Train Loss: 11.1281 | Valid Loss: 16.8842\n",
      "\n",
      "Epoch 75/800\n",
      "Train Loss: 9.5762 | Valid Loss: 10.5753\n",
      "\n",
      "Epoch 76/800\n",
      "Train Loss: 10.4478 | Valid Loss: 10.3147\n",
      "\n",
      "Epoch 77/800\n",
      "Train Loss: 8.3861 | Valid Loss: 11.5044\n",
      "\n",
      "Epoch 78/800\n",
      "Train Loss: 9.5793 | Valid Loss: 13.9282\n",
      "\n",
      "Epoch 79/800\n",
      "Train Loss: 8.3404 | Valid Loss: 9.9952\n",
      "\n",
      "Epoch 80/800\n",
      "Train Loss: 8.6625 | Valid Loss: 9.2368\n",
      "\n",
      "Epoch 81/800\n",
      "Train Loss: 7.7609 | Valid Loss: 10.1512\n",
      "\n",
      "Epoch 82/800\n",
      "Train Loss: 8.5579 | Valid Loss: 12.7520\n",
      "\n",
      "Epoch 83/800\n",
      "Train Loss: 7.7347 | Valid Loss: 8.3398\n",
      "⭐ Saved best model at epoch 83, val loss = 8.3398\n",
      "\n",
      "Epoch 84/800\n",
      "Train Loss: 8.0719 | Valid Loss: 8.5002\n",
      "\n",
      "Epoch 85/800\n",
      "Train Loss: 7.3928 | Valid Loss: 9.9712\n",
      "\n",
      "Epoch 86/800\n",
      "Train Loss: 7.6813 | Valid Loss: 11.6750\n",
      "\n",
      "Epoch 87/800\n",
      "Train Loss: 7.4608 | Valid Loss: 8.1978\n",
      "⭐ Saved best model at epoch 87, val loss = 8.1978\n",
      "\n",
      "Epoch 88/800\n",
      "Train Loss: 7.2696 | Valid Loss: 7.6065\n",
      "⭐ Saved best model at epoch 88, val loss = 7.6065\n",
      "\n",
      "Epoch 89/800\n",
      "Train Loss: 6.9487 | Valid Loss: 9.5553\n",
      "\n",
      "Epoch 90/800\n",
      "Train Loss: 6.9852 | Valid Loss: 9.7519\n",
      "\n",
      "Epoch 91/800\n",
      "Train Loss: 6.7486 | Valid Loss: 7.4194\n",
      "⭐ Saved best model at epoch 91, val loss = 7.4194\n",
      "\n",
      "Epoch 92/800\n",
      "Train Loss: 6.3313 | Valid Loss: 7.4361\n",
      "\n",
      "Epoch 93/800\n",
      "Train Loss: 6.0611 | Valid Loss: 8.3427\n",
      "\n",
      "Epoch 94/800\n",
      "Train Loss: 6.1259 | Valid Loss: 7.9093\n",
      "\n",
      "Epoch 95/800\n",
      "Train Loss: 5.9605 | Valid Loss: 7.3378\n",
      "⭐ Saved best model at epoch 95, val loss = 7.3378\n",
      "\n",
      "Epoch 96/800\n",
      "Train Loss: 5.9961 | Valid Loss: 6.7625\n",
      "⭐ Saved best model at epoch 96, val loss = 6.7625\n",
      "\n",
      "Epoch 97/800\n",
      "Train Loss: 5.6218 | Valid Loss: 8.3562\n",
      "\n",
      "Epoch 98/800\n",
      "Train Loss: 5.4246 | Valid Loss: 6.9463\n",
      "\n",
      "Epoch 99/800\n",
      "Train Loss: 5.4984 | Valid Loss: 6.4409\n",
      "⭐ Saved best model at epoch 99, val loss = 6.4409\n",
      "\n",
      "Epoch 100/800\n",
      "Train Loss: 5.0071 | Valid Loss: 7.0169\n",
      "\n",
      "Epoch 101/800\n",
      "Train Loss: 5.3192 | Valid Loss: 7.5970\n",
      "\n",
      "Epoch 102/800\n",
      "Train Loss: 4.9924 | Valid Loss: 6.2517\n",
      "⭐ Saved best model at epoch 102, val loss = 6.2517\n",
      "\n",
      "Epoch 103/800\n",
      "Train Loss: 4.8359 | Valid Loss: 5.7488\n",
      "⭐ Saved best model at epoch 103, val loss = 5.7488\n",
      "\n",
      "Epoch 104/800\n",
      "Train Loss: 4.7316 | Valid Loss: 6.8905\n",
      "\n",
      "Epoch 105/800\n",
      "Train Loss: 4.7991 | Valid Loss: 6.4333\n",
      "\n",
      "Epoch 106/800\n",
      "Train Loss: 4.6197 | Valid Loss: 5.4302\n",
      "⭐ Saved best model at epoch 106, val loss = 5.4302\n",
      "\n",
      "Epoch 107/800\n",
      "Train Loss: 4.8905 | Valid Loss: 7.3372\n",
      "\n",
      "Epoch 108/800\n",
      "Train Loss: 4.3653 | Valid Loss: 5.6486\n",
      "\n",
      "Epoch 109/800\n",
      "Train Loss: 4.6142 | Valid Loss: 5.4817\n",
      "\n",
      "Epoch 110/800\n",
      "Train Loss: 4.5096 | Valid Loss: 6.8115\n",
      "\n",
      "Epoch 111/800\n",
      "Train Loss: 4.1682 | Valid Loss: 5.4223\n",
      "⭐ Saved best model at epoch 111, val loss = 5.4223\n",
      "\n",
      "Epoch 112/800\n",
      "Train Loss: 4.4977 | Valid Loss: 4.6744\n",
      "⭐ Saved best model at epoch 112, val loss = 4.6744\n",
      "\n",
      "Epoch 113/800\n",
      "Train Loss: 4.3279 | Valid Loss: 6.5770\n",
      "\n",
      "Epoch 114/800\n",
      "Train Loss: 4.0833 | Valid Loss: 5.1171\n",
      "\n",
      "Epoch 115/800\n",
      "Train Loss: 3.8993 | Valid Loss: 4.7150\n",
      "\n",
      "Epoch 116/800\n",
      "Train Loss: 3.8702 | Valid Loss: 5.4568\n",
      "\n",
      "Epoch 117/800\n",
      "Train Loss: 3.8501 | Valid Loss: 5.5012\n",
      "\n",
      "Epoch 118/800\n",
      "Train Loss: 3.8009 | Valid Loss: 4.5709\n",
      "⭐ Saved best model at epoch 118, val loss = 4.5709\n",
      "\n",
      "Epoch 119/800\n",
      "Train Loss: 3.6927 | Valid Loss: 4.6505\n",
      "\n",
      "Epoch 120/800\n",
      "Train Loss: 3.9941 | Valid Loss: 6.0515\n",
      "\n",
      "Epoch 121/800\n",
      "Train Loss: 3.6602 | Valid Loss: 4.3231\n",
      "⭐ Saved best model at epoch 121, val loss = 4.3231\n",
      "\n",
      "Epoch 122/800\n",
      "Train Loss: 3.7051 | Valid Loss: 4.3436\n",
      "\n",
      "Epoch 123/800\n",
      "Train Loss: 3.6611 | Valid Loss: 5.9419\n",
      "\n",
      "Epoch 124/800\n",
      "Train Loss: 3.5485 | Valid Loss: 4.6736\n",
      "\n",
      "Epoch 125/800\n",
      "Train Loss: 3.4064 | Valid Loss: 4.1742\n",
      "⭐ Saved best model at epoch 125, val loss = 4.1742\n",
      "\n",
      "Epoch 126/800\n",
      "Train Loss: 3.2254 | Valid Loss: 4.5122\n",
      "\n",
      "Epoch 127/800\n",
      "Train Loss: 3.1878 | Valid Loss: 4.8629\n",
      "\n",
      "Epoch 128/800\n",
      "Train Loss: 3.2013 | Valid Loss: 4.5353\n",
      "\n",
      "Epoch 129/800\n",
      "Train Loss: 3.2301 | Valid Loss: 3.8585\n",
      "⭐ Saved best model at epoch 129, val loss = 3.8585\n",
      "\n",
      "Epoch 130/800\n",
      "Train Loss: 3.2054 | Valid Loss: 4.4045\n",
      "\n",
      "Epoch 131/800\n",
      "Train Loss: 3.1133 | Valid Loss: 4.6272\n",
      "\n",
      "Epoch 132/800\n",
      "Train Loss: 3.1483 | Valid Loss: 3.7156\n",
      "⭐ Saved best model at epoch 132, val loss = 3.7156\n",
      "\n",
      "Epoch 133/800\n",
      "Train Loss: 3.0703 | Valid Loss: 4.2634\n",
      "\n",
      "Epoch 134/800\n",
      "Train Loss: 2.9268 | Valid Loss: 4.1768\n",
      "\n",
      "Epoch 135/800\n",
      "Train Loss: 2.8601 | Valid Loss: 4.3240\n",
      "\n",
      "Epoch 136/800\n",
      "Train Loss: 2.8078 | Valid Loss: 3.8068\n",
      "\n",
      "Epoch 137/800\n",
      "Train Loss: 2.8650 | Valid Loss: 3.5086\n",
      "⭐ Saved best model at epoch 137, val loss = 3.5086\n",
      "\n",
      "Epoch 138/800\n",
      "Train Loss: 2.7617 | Valid Loss: 4.0899\n",
      "\n",
      "Epoch 139/800\n",
      "Train Loss: 2.7621 | Valid Loss: 4.3188\n",
      "\n",
      "Epoch 140/800\n",
      "Train Loss: 2.7354 | Valid Loss: 3.3520\n",
      "⭐ Saved best model at epoch 140, val loss = 3.3520\n",
      "\n",
      "Epoch 141/800\n",
      "Train Loss: 2.6917 | Valid Loss: 3.4139\n",
      "\n",
      "Epoch 142/800\n",
      "Train Loss: 2.8965 | Valid Loss: 4.9241\n",
      "\n",
      "Epoch 143/800\n",
      "Train Loss: 2.6566 | Valid Loss: 3.1904\n",
      "⭐ Saved best model at epoch 143, val loss = 3.1904\n",
      "\n",
      "Epoch 144/800\n",
      "Train Loss: 2.6317 | Valid Loss: 3.1651\n",
      "⭐ Saved best model at epoch 144, val loss = 3.1651\n",
      "\n",
      "Epoch 145/800\n",
      "Train Loss: 2.7810 | Valid Loss: 4.5824\n",
      "\n",
      "Epoch 146/800\n",
      "Train Loss: 2.4731 | Valid Loss: 3.6031\n",
      "\n",
      "Epoch 147/800\n",
      "Train Loss: 2.6860 | Valid Loss: 3.0194\n",
      "⭐ Saved best model at epoch 147, val loss = 3.0194\n",
      "\n",
      "Epoch 148/800\n",
      "Train Loss: 2.4627 | Valid Loss: 4.1661\n",
      "\n",
      "Epoch 149/800\n",
      "Train Loss: 2.4774 | Valid Loss: 3.9612\n",
      "\n",
      "Epoch 150/800\n",
      "Train Loss: 2.4541 | Valid Loss: 2.9602\n",
      "⭐ Saved best model at epoch 150, val loss = 2.9602\n",
      "\n",
      "Epoch 151/800\n",
      "Train Loss: 2.2927 | Valid Loss: 3.2726\n",
      "\n",
      "Epoch 152/800\n",
      "Train Loss: 2.2404 | Valid Loss: 3.4719\n",
      "\n",
      "Epoch 153/800\n",
      "Train Loss: 2.3023 | Valid Loss: 3.2040\n",
      "\n",
      "Epoch 154/800\n",
      "Train Loss: 2.2582 | Valid Loss: 3.4882\n",
      "\n",
      "Epoch 155/800\n",
      "Train Loss: 2.2005 | Valid Loss: 3.3570\n",
      "\n",
      "Epoch 156/800\n",
      "Train Loss: 2.2165 | Valid Loss: 2.7952\n",
      "⭐ Saved best model at epoch 156, val loss = 2.7952\n",
      "\n",
      "Epoch 157/800\n",
      "Train Loss: 2.1201 | Valid Loss: 3.4570\n",
      "\n",
      "Epoch 158/800\n",
      "Train Loss: 2.1275 | Valid Loss: 3.6088\n",
      "\n",
      "Epoch 159/800\n",
      "Train Loss: 2.2089 | Valid Loss: 2.6559\n",
      "⭐ Saved best model at epoch 159, val loss = 2.6559\n",
      "\n",
      "Epoch 160/800\n",
      "Train Loss: 2.0943 | Valid Loss: 3.0982\n",
      "\n",
      "Epoch 161/800\n",
      "Train Loss: 2.1226 | Valid Loss: 3.5992\n",
      "\n",
      "Epoch 162/800\n",
      "Train Loss: 2.0627 | Valid Loss: 2.7349\n",
      "\n",
      "Epoch 163/800\n",
      "Train Loss: 1.9939 | Valid Loss: 2.9309\n",
      "\n",
      "Epoch 164/800\n",
      "Train Loss: 1.9651 | Valid Loss: 3.1820\n",
      "\n",
      "Epoch 165/800\n",
      "Train Loss: 1.9710 | Valid Loss: 2.6051\n",
      "⭐ Saved best model at epoch 165, val loss = 2.6051\n",
      "\n",
      "Epoch 166/800\n",
      "Train Loss: 1.9248 | Valid Loss: 2.9507\n",
      "\n",
      "Epoch 167/800\n",
      "Train Loss: 1.9404 | Valid Loss: 3.0021\n",
      "\n",
      "Epoch 168/800\n",
      "Train Loss: 1.9513 | Valid Loss: 2.5233\n",
      "⭐ Saved best model at epoch 168, val loss = 2.5233\n",
      "\n",
      "Epoch 169/800\n",
      "Train Loss: 1.9204 | Valid Loss: 2.9059\n",
      "\n",
      "Epoch 170/800\n",
      "Train Loss: 1.8774 | Valid Loss: 3.4013\n",
      "\n",
      "Epoch 171/800\n",
      "Train Loss: 2.0083 | Valid Loss: 2.2044\n",
      "⭐ Saved best model at epoch 171, val loss = 2.2044\n",
      "\n",
      "Epoch 172/800\n",
      "Train Loss: 1.8970 | Valid Loss: 3.0543\n",
      "\n",
      "Epoch 173/800\n",
      "Train Loss: 1.7767 | Valid Loss: 3.3285\n",
      "\n",
      "Epoch 174/800\n",
      "Train Loss: 1.8126 | Valid Loss: 2.3522\n",
      "\n",
      "Epoch 175/800\n",
      "Train Loss: 1.7158 | Valid Loss: 2.4183\n",
      "\n",
      "Epoch 176/800\n",
      "Train Loss: 1.7490 | Valid Loss: 2.9445\n",
      "\n",
      "Epoch 177/800\n",
      "Train Loss: 1.7848 | Valid Loss: 2.9819\n",
      "\n",
      "Epoch 178/800\n",
      "Train Loss: 1.8562 | Valid Loss: 2.0770\n",
      "⭐ Saved best model at epoch 178, val loss = 2.0770\n",
      "\n",
      "Epoch 179/800\n",
      "Train Loss: 1.6621 | Valid Loss: 2.5948\n",
      "\n",
      "Epoch 180/800\n",
      "Train Loss: 2.2766 | Valid Loss: 4.4880\n",
      "\n",
      "Epoch 181/800\n",
      "Train Loss: 2.9720 | Valid Loss: 2.0795\n",
      "\n",
      "Epoch 182/800\n",
      "Train Loss: 1.7275 | Valid Loss: 2.1595\n",
      "\n",
      "Epoch 183/800\n",
      "Train Loss: 3.2297 | Valid Loss: 6.2705\n",
      "\n",
      "Epoch 184/800\n",
      "Train Loss: 1.8785 | Valid Loss: 1.9372\n",
      "⭐ Saved best model at epoch 184, val loss = 1.9372\n",
      "\n",
      "Epoch 185/800\n",
      "Train Loss: 2.2066 | Valid Loss: 1.8414\n",
      "⭐ Saved best model at epoch 185, val loss = 1.8414\n",
      "\n",
      "Epoch 186/800\n",
      "Train Loss: 2.0977 | Valid Loss: 3.8114\n",
      "\n",
      "Epoch 187/800\n",
      "Train Loss: 1.9039 | Valid Loss: 3.5004\n",
      "\n",
      "Epoch 188/800\n",
      "Train Loss: 2.3777 | Valid Loss: 1.8670\n",
      "\n",
      "Epoch 189/800\n",
      "Train Loss: 1.7177 | Valid Loss: 2.5208\n",
      "\n",
      "Epoch 190/800\n",
      "Train Loss: 2.1581 | Valid Loss: 4.3505\n",
      "\n",
      "Epoch 191/800\n",
      "Train Loss: 1.6574 | Valid Loss: 2.3416\n",
      "\n",
      "Epoch 192/800\n",
      "Train Loss: 2.0624 | Valid Loss: 1.8991\n",
      "\n",
      "Epoch 193/800\n",
      "Train Loss: 1.5849 | Valid Loss: 2.7499\n",
      "\n",
      "Epoch 194/800\n",
      "Train Loss: 2.3342 | Valid Loss: 4.5157\n",
      "\n",
      "Epoch 195/800\n",
      "Train Loss: 2.1321 | Valid Loss: 1.7783\n",
      "⭐ Saved best model at epoch 195, val loss = 1.7783\n",
      "\n",
      "Epoch 196/800\n",
      "Train Loss: 1.7559 | Valid Loss: 1.8482\n",
      "\n",
      "Epoch 197/800\n",
      "Train Loss: 2.1535 | Valid Loss: 4.2721\n",
      "\n",
      "Epoch 198/800\n",
      "Train Loss: 1.5314 | Valid Loss: 2.4503\n",
      "\n",
      "Epoch 199/800\n",
      "Train Loss: 1.8778 | Valid Loss: 1.7215\n",
      "⭐ Saved best model at epoch 199, val loss = 1.7215\n",
      "\n",
      "Epoch 200/800\n",
      "Train Loss: 1.4993 | Valid Loss: 2.5318\n",
      "\n",
      "Epoch 201/800\n",
      "Train Loss: 1.6252 | Valid Loss: 3.1997\n",
      "\n",
      "Epoch 202/800\n",
      "Train Loss: 1.4848 | Valid Loss: 2.2791\n",
      "\n",
      "Epoch 203/800\n",
      "Train Loss: 1.6847 | Valid Loss: 1.7875\n",
      "\n",
      "Epoch 204/800\n",
      "Train Loss: 1.4572 | Valid Loss: 2.3582\n",
      "\n",
      "Epoch 205/800\n",
      "Train Loss: 1.7074 | Valid Loss: 3.4480\n",
      "\n",
      "Epoch 206/800\n",
      "Train Loss: 1.4118 | Valid Loss: 2.1181\n",
      "\n",
      "Epoch 207/800\n",
      "Train Loss: 1.6123 | Valid Loss: 1.7006\n",
      "⭐ Saved best model at epoch 207, val loss = 1.7006\n",
      "\n",
      "Epoch 208/800\n",
      "Train Loss: 1.4451 | Valid Loss: 2.3323\n",
      "\n",
      "Epoch 209/800\n",
      "Train Loss: 1.5841 | Valid Loss: 3.1321\n",
      "\n",
      "Epoch 210/800\n",
      "Train Loss: 1.4149 | Valid Loss: 1.9161\n",
      "\n",
      "Epoch 211/800\n",
      "Train Loss: 1.4599 | Valid Loss: 1.7458\n",
      "\n",
      "Epoch 212/800\n",
      "Train Loss: 1.4491 | Valid Loss: 2.4980\n",
      "\n",
      "Epoch 213/800\n",
      "Train Loss: 1.4791 | Valid Loss: 2.8546\n",
      "\n",
      "Epoch 214/800\n",
      "Train Loss: 1.3919 | Valid Loss: 1.9833\n",
      "\n",
      "Epoch 215/800\n",
      "Train Loss: 1.4745 | Valid Loss: 1.6432\n",
      "⭐ Saved best model at epoch 215, val loss = 1.6432\n",
      "\n",
      "Epoch 216/800\n",
      "Train Loss: 1.3548 | Valid Loss: 2.3012\n",
      "\n",
      "Epoch 217/800\n",
      "Train Loss: 1.4957 | Valid Loss: 3.2123\n",
      "\n",
      "Epoch 218/800\n",
      "Train Loss: 1.5175 | Valid Loss: 1.5794\n",
      "⭐ Saved best model at epoch 218, val loss = 1.5794\n",
      "\n",
      "Epoch 219/800\n",
      "Train Loss: 1.2860 | Valid Loss: 1.7618\n",
      "\n",
      "Epoch 220/800\n",
      "Train Loss: 1.2721 | Valid Loss: 2.4855\n",
      "\n",
      "Epoch 221/800\n",
      "Train Loss: 1.3914 | Valid Loss: 2.6930\n",
      "\n",
      "Epoch 222/800\n",
      "Train Loss: 1.3015 | Valid Loss: 1.6891\n",
      "\n",
      "Epoch 223/800\n",
      "Train Loss: 1.3721 | Valid Loss: 1.4885\n",
      "⭐ Saved best model at epoch 223, val loss = 1.4885\n",
      "\n",
      "Epoch 224/800\n",
      "Train Loss: 1.2800 | Valid Loss: 2.7132\n",
      "\n",
      "Epoch 225/800\n",
      "Train Loss: 1.2723 | Valid Loss: 2.6098\n",
      "\n",
      "Epoch 226/800\n",
      "Train Loss: 1.3096 | Valid Loss: 1.5359\n",
      "\n",
      "Epoch 227/800\n",
      "Train Loss: 1.1570 | Valid Loss: 1.9370\n",
      "\n",
      "Epoch 228/800\n",
      "Train Loss: 1.1593 | Valid Loss: 2.2112\n",
      "\n",
      "Epoch 229/800\n",
      "Train Loss: 1.1379 | Valid Loss: 2.0016\n",
      "\n",
      "Epoch 230/800\n",
      "Train Loss: 1.1633 | Valid Loss: 1.5838\n",
      "\n",
      "Epoch 231/800\n",
      "Train Loss: 1.1078 | Valid Loss: 1.9929\n",
      "\n",
      "Epoch 232/800\n",
      "Train Loss: 1.1082 | Valid Loss: 1.9318\n",
      "\n",
      "Epoch 233/800\n",
      "Train Loss: 1.0841 | Valid Loss: 1.9259\n",
      "\n",
      "Epoch 234/800\n",
      "Train Loss: 1.0853 | Valid Loss: 1.6051\n",
      "\n",
      "Epoch 235/800\n",
      "Train Loss: 1.1301 | Valid Loss: 2.2574\n",
      "\n",
      "Epoch 236/800\n",
      "Train Loss: 1.0128 | Valid Loss: 1.8041\n",
      "\n",
      "Epoch 237/800\n",
      "Train Loss: 1.0703 | Valid Loss: 1.6502\n",
      "\n",
      "Epoch 238/800\n",
      "Train Loss: 1.0370 | Valid Loss: 1.9573\n",
      "\n",
      "Epoch 239/800\n",
      "Train Loss: 1.0262 | Valid Loss: 1.7963\n",
      "\n",
      "Epoch 240/800\n",
      "Train Loss: 1.0520 | Valid Loss: 1.8210\n",
      "\n",
      "Epoch 241/800\n",
      "Train Loss: 1.0215 | Valid Loss: 1.8625\n",
      "\n",
      "Epoch 242/800\n",
      "Train Loss: 1.0208 | Valid Loss: 1.7255\n",
      "\n",
      "Epoch 243/800\n",
      "Train Loss: 0.9717 | Valid Loss: 1.8759\n",
      "\n",
      "Epoch 244/800\n",
      "Train Loss: 0.9932 | Valid Loss: 1.7938\n",
      "\n",
      "Epoch 245/800\n",
      "Train Loss: 0.9842 | Valid Loss: 1.5610\n",
      "\n",
      "Epoch 246/800\n",
      "Train Loss: 1.0179 | Valid Loss: 1.4627\n",
      "⭐ Saved best model at epoch 246, val loss = 1.4627\n",
      "\n",
      "Epoch 247/800\n",
      "Train Loss: 1.1502 | Valid Loss: 2.5562\n",
      "\n",
      "Epoch 248/800\n",
      "Train Loss: 1.2550 | Valid Loss: 1.0775\n",
      "⭐ Saved best model at epoch 248, val loss = 1.0775\n",
      "\n",
      "Epoch 249/800\n",
      "Train Loss: 0.9902 | Valid Loss: 1.3227\n",
      "\n",
      "Epoch 250/800\n",
      "Train Loss: 1.3242 | Valid Loss: 3.2076\n",
      "\n",
      "Epoch 251/800\n",
      "Train Loss: 0.9654 | Valid Loss: 1.3660\n",
      "\n",
      "Epoch 252/800\n",
      "Train Loss: 1.0787 | Valid Loss: 1.2317\n",
      "\n",
      "Epoch 253/800\n",
      "Train Loss: 1.0702 | Valid Loss: 2.4845\n",
      "\n",
      "Epoch 254/800\n",
      "Train Loss: 0.9840 | Valid Loss: 1.4862\n",
      "\n",
      "Epoch 255/800\n",
      "Train Loss: 0.9849 | Valid Loss: 1.7060\n",
      "\n",
      "Epoch 256/800\n",
      "Train Loss: 0.9517 | Valid Loss: 1.5580\n",
      "\n",
      "Epoch 257/800\n",
      "Train Loss: 0.9974 | Valid Loss: 1.4390\n",
      "\n",
      "Epoch 258/800\n",
      "Train Loss: 0.9326 | Valid Loss: 1.9233\n",
      "\n",
      "Epoch 259/800\n",
      "Train Loss: 0.9274 | Valid Loss: 1.7080\n",
      "\n",
      "Epoch 260/800\n",
      "Train Loss: 0.9662 | Valid Loss: 1.2294\n",
      "\n",
      "Epoch 261/800\n",
      "Train Loss: 0.8900 | Valid Loss: 1.7431\n",
      "\n",
      "Epoch 262/800\n",
      "Train Loss: 0.9237 | Valid Loss: 1.8446\n",
      "\n",
      "Epoch 263/800\n",
      "Train Loss: 0.9015 | Valid Loss: 1.3991\n",
      "\n",
      "Epoch 264/800\n",
      "Train Loss: 0.8812 | Valid Loss: 1.4808\n",
      "\n",
      "Epoch 265/800\n",
      "Train Loss: 0.8675 | Valid Loss: 1.8656\n",
      "\n",
      "Epoch 266/800\n",
      "Train Loss: 0.8639 | Valid Loss: 1.4121\n",
      "\n",
      "Epoch 267/800\n",
      "Train Loss: 0.8579 | Valid Loss: 1.3508\n",
      "\n",
      "Epoch 268/800\n",
      "Train Loss: 0.8628 | Valid Loss: 1.6301\n",
      "\n",
      "Epoch 269/800\n",
      "Train Loss: 0.8961 | Valid Loss: 1.8228\n",
      "\n",
      "Epoch 270/800\n",
      "Train Loss: 0.8858 | Valid Loss: 1.1450\n",
      "\n",
      "Epoch 271/800\n",
      "Train Loss: 0.8629 | Valid Loss: 1.2705\n",
      "\n",
      "Epoch 272/800\n",
      "Train Loss: 0.9280 | Valid Loss: 2.0211\n",
      "\n",
      "Epoch 273/800\n",
      "Train Loss: 0.7953 | Valid Loss: 1.5526\n",
      "\n",
      "Epoch 274/800\n",
      "Train Loss: 0.8474 | Valid Loss: 1.1808\n",
      "\n",
      "Epoch 275/800\n",
      "Train Loss: 0.8084 | Valid Loss: 1.2986\n",
      "\n",
      "Epoch 276/800\n",
      "Train Loss: 0.8508 | Valid Loss: 1.9372\n",
      "\n",
      "Epoch 277/800\n",
      "Train Loss: 0.7770 | Valid Loss: 1.5065\n",
      "\n",
      "Epoch 278/800\n",
      "Train Loss: 0.7505 | Valid Loss: 1.2910\n",
      "\n",
      "Epoch 279/800\n",
      "Train Loss: 0.8049 | Valid Loss: 1.2136\n",
      "\n",
      "Epoch 280/800\n",
      "Train Loss: 0.8683 | Valid Loss: 2.0743\n",
      "\n",
      "Epoch 281/800\n",
      "Train Loss: 0.7682 | Valid Loss: 1.4393\n",
      "\n",
      "Epoch 282/800\n",
      "Train Loss: 0.8567 | Valid Loss: 1.0252\n",
      "⭐ Saved best model at epoch 282, val loss = 1.0252\n",
      "\n",
      "Epoch 283/800\n",
      "Train Loss: 0.7334 | Valid Loss: 1.3297\n",
      "\n",
      "Epoch 284/800\n",
      "Train Loss: 0.9392 | Valid Loss: 2.3912\n",
      "\n",
      "Epoch 285/800\n",
      "Train Loss: 0.8467 | Valid Loss: 1.0120\n",
      "⭐ Saved best model at epoch 285, val loss = 1.0120\n",
      "\n",
      "Epoch 286/800\n",
      "Train Loss: 0.8353 | Valid Loss: 0.9334\n",
      "⭐ Saved best model at epoch 286, val loss = 0.9334\n",
      "\n",
      "Epoch 287/800\n",
      "Train Loss: 0.8502 | Valid Loss: 2.0121\n",
      "\n",
      "Epoch 288/800\n",
      "Train Loss: 0.7629 | Valid Loss: 1.7428\n",
      "\n",
      "Epoch 289/800\n",
      "Train Loss: 0.7740 | Valid Loss: 1.0949\n",
      "\n",
      "Epoch 290/800\n",
      "Train Loss: 0.7681 | Valid Loss: 1.0889\n",
      "\n",
      "Epoch 291/800\n",
      "Train Loss: 0.7834 | Valid Loss: 1.7216\n",
      "\n",
      "Epoch 292/800\n",
      "Train Loss: 0.7369 | Valid Loss: 1.6358\n",
      "\n",
      "Epoch 293/800\n",
      "Train Loss: 0.8052 | Valid Loss: 0.9885\n",
      "\n",
      "Epoch 294/800\n",
      "Train Loss: 0.7309 | Valid Loss: 1.1218\n",
      "\n",
      "Epoch 295/800\n",
      "Train Loss: 0.7501 | Valid Loss: 1.8110\n",
      "\n",
      "Epoch 296/800\n",
      "Train Loss: 0.7248 | Valid Loss: 1.5023\n",
      "\n",
      "Epoch 297/800\n",
      "Train Loss: 0.7320 | Valid Loss: 1.0508\n",
      "\n",
      "Epoch 298/800\n",
      "Train Loss: 0.7022 | Valid Loss: 1.1097\n",
      "\n",
      "Epoch 299/800\n",
      "Train Loss: 0.7959 | Valid Loss: 1.8509\n",
      "\n",
      "Epoch 300/800\n",
      "Train Loss: 0.6773 | Valid Loss: 1.0616\n",
      "\n",
      "Epoch 301/800\n",
      "Train Loss: 0.7584 | Valid Loss: 0.8954\n",
      "⭐ Saved best model at epoch 301, val loss = 0.8954\n",
      "\n",
      "Epoch 302/800\n",
      "Train Loss: 0.7684 | Valid Loss: 1.7640\n",
      "\n",
      "Epoch 303/800\n",
      "Train Loss: 0.6970 | Valid Loss: 1.5003\n",
      "\n",
      "Epoch 304/800\n",
      "Train Loss: 0.7077 | Valid Loss: 0.9862\n",
      "\n",
      "Epoch 305/800\n",
      "Train Loss: 0.6514 | Valid Loss: 1.0549\n",
      "\n",
      "Epoch 306/800\n",
      "Train Loss: 0.7506 | Valid Loss: 1.8091\n",
      "\n",
      "Epoch 307/800\n",
      "Train Loss: 0.6733 | Valid Loss: 1.0248\n",
      "\n",
      "Epoch 308/800\n",
      "Train Loss: 0.6461 | Valid Loss: 0.9594\n",
      "\n",
      "Epoch 309/800\n",
      "Train Loss: 0.6674 | Valid Loss: 1.5097\n",
      "\n",
      "Epoch 310/800\n",
      "Train Loss: 0.6512 | Valid Loss: 1.4581\n",
      "\n",
      "Epoch 311/800\n",
      "Train Loss: 0.6647 | Valid Loss: 0.8950\n",
      "⭐ Saved best model at epoch 311, val loss = 0.8950\n",
      "\n",
      "Epoch 312/800\n",
      "Train Loss: 0.6509 | Valid Loss: 1.0078\n",
      "\n",
      "Epoch 313/800\n",
      "Train Loss: 0.7284 | Valid Loss: 1.8145\n",
      "\n",
      "Epoch 314/800\n",
      "Train Loss: 0.6445 | Valid Loss: 1.1787\n",
      "\n",
      "Epoch 315/800\n",
      "Train Loss: 0.7175 | Valid Loss: 0.8132\n",
      "⭐ Saved best model at epoch 315, val loss = 0.8132\n",
      "\n",
      "Epoch 316/800\n",
      "Train Loss: 0.6299 | Valid Loss: 1.3720\n",
      "\n",
      "Epoch 317/800\n",
      "Train Loss: 0.6559 | Valid Loss: 1.6388\n",
      "\n",
      "Epoch 318/800\n",
      "Train Loss: 0.6985 | Valid Loss: 0.8395\n",
      "\n",
      "Epoch 319/800\n",
      "Train Loss: 0.6086 | Valid Loss: 1.0720\n",
      "\n",
      "Epoch 320/800\n",
      "Train Loss: 0.6637 | Valid Loss: 1.6428\n",
      "\n",
      "Epoch 321/800\n",
      "Train Loss: 0.5849 | Valid Loss: 1.1790\n",
      "\n",
      "Epoch 322/800\n",
      "Train Loss: 0.6291 | Valid Loss: 0.8762\n",
      "\n",
      "Epoch 323/800\n",
      "Train Loss: 0.5750 | Valid Loss: 1.1150\n",
      "\n",
      "Epoch 324/800\n",
      "Train Loss: 0.6773 | Valid Loss: 1.6826\n",
      "\n",
      "Epoch 325/800\n",
      "Train Loss: 0.5594 | Valid Loss: 1.0635\n",
      "\n",
      "Epoch 326/800\n",
      "Train Loss: 0.6699 | Valid Loss: 0.7626\n",
      "⭐ Saved best model at epoch 326, val loss = 0.7626\n",
      "\n",
      "Epoch 327/800\n",
      "Train Loss: 0.6035 | Valid Loss: 1.3550\n",
      "\n",
      "Epoch 328/800\n",
      "Train Loss: 0.6296 | Valid Loss: 1.5340\n",
      "\n",
      "Epoch 329/800\n",
      "Train Loss: 0.6026 | Valid Loss: 0.8937\n",
      "\n",
      "Epoch 330/800\n",
      "Train Loss: 0.6118 | Valid Loss: 0.8085\n",
      "\n",
      "Epoch 331/800\n",
      "Train Loss: 0.5958 | Valid Loss: 1.4210\n",
      "\n",
      "Epoch 332/800\n",
      "Train Loss: 0.5747 | Valid Loss: 1.3399\n",
      "\n",
      "Epoch 333/800\n",
      "Train Loss: 0.5869 | Valid Loss: 0.8298\n",
      "\n",
      "Epoch 334/800\n",
      "Train Loss: 0.5890 | Valid Loss: 0.8577\n",
      "\n",
      "Epoch 335/800\n",
      "Train Loss: 0.6228 | Valid Loss: 1.5785\n",
      "\n",
      "Epoch 336/800\n",
      "Train Loss: 0.5516 | Valid Loss: 1.2298\n",
      "\n",
      "Epoch 337/800\n",
      "Train Loss: 0.6487 | Valid Loss: 0.7257\n",
      "⭐ Saved best model at epoch 337, val loss = 0.7257\n",
      "\n",
      "Epoch 338/800\n",
      "Train Loss: 0.5471 | Valid Loss: 0.9955\n",
      "\n",
      "Epoch 339/800\n",
      "Train Loss: 0.6333 | Valid Loss: 1.4667\n",
      "\n",
      "Epoch 340/800\n",
      "Train Loss: 0.5478 | Valid Loss: 0.9835\n",
      "\n",
      "Epoch 341/800\n",
      "Train Loss: 0.6603 | Valid Loss: 0.6905\n",
      "⭐ Saved best model at epoch 341, val loss = 0.6905\n",
      "\n",
      "Epoch 342/800\n",
      "Train Loss: 0.5190 | Valid Loss: 1.1153\n",
      "\n",
      "Epoch 343/800\n",
      "Train Loss: 0.6946 | Valid Loss: 1.8409\n",
      "\n",
      "Epoch 344/800\n",
      "Train Loss: 0.5742 | Valid Loss: 0.7312\n",
      "\n",
      "Epoch 345/800\n",
      "Train Loss: 0.5976 | Valid Loss: 0.7035\n",
      "\n",
      "Epoch 346/800\n",
      "Train Loss: 0.5310 | Valid Loss: 1.2367\n",
      "\n",
      "Epoch 347/800\n",
      "Train Loss: 0.5491 | Valid Loss: 1.2831\n",
      "\n",
      "Epoch 348/800\n",
      "Train Loss: 0.5153 | Valid Loss: 0.9300\n",
      "\n",
      "Epoch 349/800\n",
      "Train Loss: 0.5507 | Valid Loss: 0.7537\n",
      "\n",
      "Epoch 350/800\n",
      "Train Loss: 0.5281 | Valid Loss: 1.1673\n",
      "\n",
      "Epoch 351/800\n",
      "Train Loss: 0.4911 | Valid Loss: 0.9173\n",
      "\n",
      "Epoch 352/800\n",
      "Train Loss: 0.5080 | Valid Loss: 1.0442\n",
      "\n",
      "Epoch 353/800\n",
      "Train Loss: 0.5050 | Valid Loss: 0.9100\n",
      "\n",
      "Epoch 354/800\n",
      "Train Loss: 0.5174 | Valid Loss: 0.8802\n",
      "\n",
      "Epoch 355/800\n",
      "Train Loss: 0.5060 | Valid Loss: 1.1885\n",
      "\n",
      "Epoch 356/800\n",
      "Train Loss: 0.5002 | Valid Loss: 0.8956\n",
      "\n",
      "Epoch 357/800\n",
      "Train Loss: 0.4791 | Valid Loss: 0.8677\n",
      "\n",
      "Epoch 358/800\n",
      "Train Loss: 0.4782 | Valid Loss: 0.8945\n",
      "\n",
      "Epoch 359/800\n",
      "Train Loss: 0.5057 | Valid Loss: 1.2092\n",
      "\n",
      "Epoch 360/800\n",
      "Train Loss: 0.4918 | Valid Loss: 0.8557\n",
      "\n",
      "Epoch 361/800\n",
      "Train Loss: 0.4922 | Valid Loss: 1.0978\n",
      "\n",
      "Epoch 362/800\n",
      "Train Loss: 0.4838 | Valid Loss: 1.0799\n",
      "\n",
      "Epoch 363/800\n",
      "Train Loss: 0.5047 | Valid Loss: 0.7730\n",
      "\n",
      "Epoch 364/800\n",
      "Train Loss: 0.4801 | Valid Loss: 1.1290\n",
      "\n",
      "Epoch 365/800\n",
      "Train Loss: 0.4822 | Valid Loss: 0.8076\n",
      "\n",
      "Epoch 366/800\n",
      "Train Loss: 0.4518 | Valid Loss: 0.9315\n",
      "\n",
      "Epoch 367/800\n",
      "Train Loss: 0.4757 | Valid Loss: 1.0800\n",
      "\n",
      "Epoch 368/800\n",
      "Train Loss: 0.4562 | Valid Loss: 0.8399\n",
      "\n",
      "Epoch 369/800\n",
      "Train Loss: 0.4786 | Valid Loss: 0.9520\n",
      "\n",
      "Epoch 370/800\n",
      "Train Loss: 0.4802 | Valid Loss: 0.6830\n",
      "⭐ Saved best model at epoch 370, val loss = 0.6830\n",
      "\n",
      "Epoch 371/800\n",
      "Train Loss: 0.4480 | Valid Loss: 1.0132\n",
      "\n",
      "Epoch 372/800\n",
      "Train Loss: 0.5275 | Valid Loss: 1.3529\n",
      "\n",
      "Epoch 373/800\n",
      "Train Loss: 0.5313 | Valid Loss: 0.6342\n",
      "⭐ Saved best model at epoch 373, val loss = 0.6342\n",
      "\n",
      "Epoch 374/800\n",
      "Train Loss: 0.4545 | Valid Loss: 0.7878\n",
      "\n",
      "Epoch 375/800\n",
      "Train Loss: 0.4912 | Valid Loss: 1.2649\n",
      "\n",
      "Epoch 376/800\n",
      "Train Loss: 0.4695 | Valid Loss: 1.1191\n",
      "\n",
      "Epoch 377/800\n",
      "Train Loss: 0.5907 | Valid Loss: 0.5293\n",
      "⭐ Saved best model at epoch 377, val loss = 0.5293\n",
      "\n",
      "Epoch 378/800\n",
      "Train Loss: 0.4668 | Valid Loss: 1.0797\n",
      "\n",
      "Epoch 379/800\n",
      "Train Loss: 0.4809 | Valid Loss: 1.1626\n",
      "\n",
      "Epoch 380/800\n",
      "Train Loss: 0.4399 | Valid Loss: 0.8248\n",
      "\n",
      "Epoch 381/800\n",
      "Train Loss: 0.5292 | Valid Loss: 0.5787\n",
      "\n",
      "Epoch 382/800\n",
      "Train Loss: 0.4368 | Valid Loss: 1.0330\n",
      "\n",
      "Epoch 383/800\n",
      "Train Loss: 0.4769 | Valid Loss: 1.2117\n",
      "\n",
      "Epoch 384/800\n",
      "Train Loss: 0.4181 | Valid Loss: 0.7829\n",
      "\n",
      "Epoch 385/800\n",
      "Train Loss: 0.4768 | Valid Loss: 0.6201\n",
      "\n",
      "Epoch 386/800\n",
      "Train Loss: 0.4254 | Valid Loss: 0.8809\n",
      "\n",
      "Epoch 387/800\n",
      "Train Loss: 0.5250 | Valid Loss: 1.4168\n",
      "\n",
      "Epoch 388/800\n",
      "Train Loss: 0.4272 | Valid Loss: 0.7340\n",
      "\n",
      "Epoch 389/800\n",
      "Train Loss: 0.4521 | Valid Loss: 0.6575\n",
      "\n",
      "Epoch 390/800\n",
      "Train Loss: 0.4115 | Valid Loss: 0.7479\n",
      "\n",
      "Epoch 391/800\n",
      "Train Loss: 0.5236 | Valid Loss: 1.4324\n",
      "\n",
      "Epoch 392/800\n",
      "Train Loss: 0.4229 | Valid Loss: 0.8334\n",
      "\n",
      "Epoch 393/800\n",
      "Train Loss: 0.4635 | Valid Loss: 0.5771\n",
      "\n",
      "Epoch 394/800\n",
      "Train Loss: 0.4134 | Valid Loss: 0.7225\n",
      "\n",
      "Epoch 395/800\n",
      "Train Loss: 0.4994 | Valid Loss: 1.3969\n",
      "\n",
      "Epoch 396/800\n",
      "Train Loss: 0.4195 | Valid Loss: 0.8152\n",
      "\n",
      "Epoch 397/800\n",
      "Train Loss: 0.4250 | Valid Loss: 0.6393\n",
      "\n",
      "Epoch 398/800\n",
      "Train Loss: 0.4271 | Valid Loss: 0.6626\n",
      "\n",
      "Epoch 399/800\n",
      "Train Loss: 0.4931 | Valid Loss: 1.2585\n",
      "\n",
      "Epoch 400/800\n",
      "Train Loss: 0.4229 | Valid Loss: 1.0459\n",
      "\n",
      "Epoch 401/800\n",
      "Train Loss: 0.4524 | Valid Loss: 0.5535\n",
      "\n",
      "Epoch 402/800\n",
      "Train Loss: 0.4128 | Valid Loss: 0.6577\n",
      "\n",
      "Epoch 403/800\n",
      "Train Loss: 0.5137 | Valid Loss: 1.4719\n",
      "\n",
      "Epoch 404/800\n",
      "Train Loss: 0.4233 | Valid Loss: 0.6373\n",
      "\n",
      "Epoch 405/800\n",
      "Train Loss: 0.4034 | Valid Loss: 0.7123\n",
      "\n",
      "Epoch 406/800\n",
      "Train Loss: 0.3961 | Valid Loss: 0.7173\n",
      "\n",
      "Epoch 407/800\n",
      "Train Loss: 0.4028 | Valid Loss: 0.9138\n",
      "\n",
      "Epoch 408/800\n",
      "Train Loss: 0.4015 | Valid Loss: 0.9257\n",
      "\n",
      "Epoch 409/800\n",
      "Train Loss: 0.3869 | Valid Loss: 0.7860\n",
      "\n",
      "Epoch 410/800\n",
      "Train Loss: 0.4325 | Valid Loss: 0.5933\n",
      "\n",
      "Epoch 411/800\n",
      "Train Loss: 0.3907 | Valid Loss: 0.9434\n",
      "\n",
      "Epoch 412/800\n",
      "Train Loss: 0.4321 | Valid Loss: 1.1556\n",
      "\n",
      "Epoch 413/800\n",
      "Train Loss: 0.4067 | Valid Loss: 0.5992\n",
      "\n",
      "Epoch 414/800\n",
      "Train Loss: 0.4291 | Valid Loss: 0.5610\n",
      "\n",
      "Epoch 415/800\n",
      "Train Loss: 0.4454 | Valid Loss: 1.2406\n",
      "\n",
      "Epoch 416/800\n",
      "Train Loss: 0.4187 | Valid Loss: 1.1094\n",
      "\n",
      "Epoch 417/800\n",
      "Train Loss: 0.4983 | Valid Loss: 0.4952\n",
      "⭐ Saved best model at epoch 417, val loss = 0.4952\n",
      "\n",
      "Epoch 418/800\n",
      "Train Loss: 0.4003 | Valid Loss: 0.5999\n",
      "\n",
      "Epoch 419/800\n",
      "Train Loss: 0.5693 | Valid Loss: 1.5030\n",
      "\n",
      "Epoch 420/800\n",
      "Train Loss: 0.3764 | Valid Loss: 0.8166\n",
      "\n",
      "Epoch 421/800\n",
      "Train Loss: 0.5471 | Valid Loss: 0.4246\n",
      "⭐ Saved best model at epoch 421, val loss = 0.4246\n",
      "\n",
      "Epoch 422/800\n",
      "Train Loss: 0.3881 | Valid Loss: 0.6172\n",
      "\n",
      "Epoch 423/800\n",
      "Train Loss: 0.7431 | Valid Loss: 1.9131\n",
      "\n",
      "Epoch 424/800\n",
      "Train Loss: 0.5199 | Valid Loss: 0.4305\n",
      "\n",
      "Epoch 425/800\n",
      "Train Loss: 0.5445 | Valid Loss: 0.4500\n",
      "\n",
      "Epoch 426/800\n",
      "Train Loss: 2.9931 | Valid Loss: 5.4898\n",
      "\n",
      "Epoch 427/800\n",
      "Train Loss: 10.0013 | Valid Loss: 6.8040\n",
      "\n",
      "Epoch 428/800\n",
      "Train Loss: 331.4391 | Valid Loss: 406.9276\n",
      "\n",
      "Epoch 429/800\n",
      "Train Loss: 595.7913 | Valid Loss: 635.2105\n",
      "\n",
      "Epoch 430/800\n",
      "Train Loss: 38064.4375 | Valid Loss: 42836.3203\n",
      "\n",
      "Epoch 431/800\n",
      "Train Loss: 1269.7982 | Valid Loss: 1361.8014\n",
      "\n",
      "Epoch 432/800\n",
      "Train Loss: 28836.9180 | Valid Loss: 32345.7266\n",
      "\n",
      "Epoch 433/800\n",
      "Train Loss: 7171.1592 | Valid Loss: 7717.6396\n",
      "\n",
      "Epoch 434/800\n",
      "Train Loss: 4839685.5000 | Valid Loss: 5480323.0000\n",
      "\n",
      "Epoch 435/800\n",
      "Train Loss: 22178.3340 | Valid Loss: 24404.3008\n",
      "\n",
      "Epoch 436/800\n",
      "Train Loss: 3208.6523 | Valid Loss: 3792.3374\n",
      "\n",
      "Epoch 437/800\n",
      "Train Loss: 410153.3750 | Valid Loss: 454749.3125\n",
      "\n",
      "Epoch 438/800\n",
      "Train Loss: 523224.4688 | Valid Loss: 585516.3125\n",
      "\n",
      "Epoch 439/800\n",
      "Train Loss: 10463.2852 | Valid Loss: 12126.6230\n",
      "\n",
      "Epoch 440/800\n",
      "Train Loss: 36220.7617 | Valid Loss: 42656.4609\n",
      "\n",
      "Epoch 441/800\n",
      "Train Loss: 659240.7500 | Valid Loss: 750008.5000\n",
      "\n",
      "Epoch 442/800\n",
      "Train Loss: 2751194.2500 | Valid Loss: 3068170.5000\n",
      "\n",
      "Epoch 443/800\n",
      "Train Loss: 15118762.0000 | Valid Loss: 16931326.0000\n",
      "\n",
      "Epoch 444/800\n",
      "Train Loss: 11976335.0000 | Valid Loss: 13359633.0000\n",
      "\n",
      "Epoch 445/800\n",
      "Train Loss: 754784.3125 | Valid Loss: 830321.5625\n",
      "\n",
      "Epoch 446/800\n",
      "Train Loss: 784570.8125 | Valid Loss: 887602.4375\n",
      "\n",
      "Epoch 447/800\n",
      "Train Loss: 799721.1250 | Valid Loss: 887343.5000\n",
      "\n",
      "Epoch 448/800\n",
      "Train Loss: 174435.4844 | Valid Loss: 195367.7969\n",
      "\n",
      "Epoch 449/800\n",
      "Train Loss: 900112.8750 | Valid Loss: 1009005.4375\n",
      "\n",
      "Epoch 450/800\n",
      "Train Loss: 214335.2031 | Valid Loss: 239973.9375\n",
      "\n",
      "Epoch 451/800\n",
      "Train Loss: 87704.7812 | Valid Loss: 99271.5469\n",
      "\n",
      "Epoch 452/800\n",
      "Train Loss: 290148.2500 | Valid Loss: 320192.6562\n",
      "\n",
      "Epoch 453/800\n",
      "Train Loss: 6436.9062 | Valid Loss: 7137.3574\n",
      "\n",
      "Epoch 454/800\n",
      "Train Loss: 123436.1328 | Valid Loss: 141547.9844\n",
      "\n",
      "Epoch 455/800\n",
      "Train Loss: 514369504.0000 | Valid Loss: 583012224.0000\n",
      "\n",
      "Epoch 456/800\n",
      "Train Loss: 8081165.5000 | Valid Loss: 9074278.0000\n",
      "\n",
      "Epoch 457/800\n",
      "Train Loss: 239301136.0000 | Valid Loss: 267310480.0000\n",
      "\n",
      "Epoch 458/800\n",
      "Train Loss: 13081931.0000 | Valid Loss: 14511348.0000\n",
      "\n",
      "Epoch 459/800\n",
      "Train Loss: 11148355.0000 | Valid Loss: 12316146.0000\n",
      "\n",
      "Epoch 460/800\n",
      "Train Loss: 2648577.2500 | Valid Loss: 2923196.2500\n",
      "\n",
      "Epoch 461/800\n",
      "Train Loss: 11859437.0000 | Valid Loss: 13215627.0000\n",
      "\n",
      "Epoch 462/800\n",
      "Train Loss: 2800704.7500 | Valid Loss: 3109272.2500\n",
      "\n",
      "Epoch 463/800\n",
      "Train Loss: 8350746.0000 | Valid Loss: 9119195.0000\n",
      "\n",
      "Epoch 464/800\n",
      "Train Loss: 2961077.5000 | Valid Loss: 3308137.5000\n",
      "\n",
      "Epoch 465/800\n",
      "Train Loss: 4840260.5000 | Valid Loss: 5485241.5000\n",
      "\n",
      "Epoch 466/800\n",
      "Train Loss: 5347867.5000 | Valid Loss: 5936256.5000\n",
      "\n",
      "Epoch 467/800\n",
      "Train Loss: 1782387.2500 | Valid Loss: 1873944.7500\n",
      "\n",
      "Epoch 468/800\n",
      "Train Loss: 4374850.0000 | Valid Loss: 5101543.0000\n",
      "\n",
      "Epoch 469/800\n",
      "Train Loss: 1932422.1250 | Valid Loss: 2188931.0000\n",
      "\n",
      "Epoch 470/800\n",
      "Train Loss: 1664304.8750 | Valid Loss: 1922533.5000\n",
      "\n",
      "Epoch 471/800\n",
      "Train Loss: 2642574.0000 | Valid Loss: 2914517.2500\n",
      "\n",
      "Epoch 472/800\n",
      "Train Loss: 1469157.2500 | Valid Loss: 1630165.7500\n",
      "\n",
      "Epoch 473/800\n",
      "Train Loss: 848881.3125 | Valid Loss: 955942.2500\n",
      "\n",
      "Epoch 474/800\n",
      "Train Loss: 1372494.3750 | Valid Loss: 1592685.0000\n",
      "\n",
      "Epoch 475/800\n",
      "Train Loss: 1283523.0000 | Valid Loss: 1433328.2500\n",
      "\n",
      "Epoch 476/800\n",
      "Train Loss: 686925.2500 | Valid Loss: 720823.2500\n",
      "\n",
      "Epoch 477/800\n",
      "Train Loss: 437244.1562 | Valid Loss: 498657.9688\n",
      "\n",
      "Epoch 478/800\n",
      "Train Loss: 590970.0625 | Valid Loss: 680468.3750\n",
      "\n",
      "Epoch 479/800\n",
      "Train Loss: 680542.5000 | Valid Loss: 735074.8750\n",
      "\n",
      "Epoch 480/800\n",
      "Train Loss: 502458.1562 | Valid Loss: 566150.3125\n",
      "\n",
      "Epoch 481/800\n",
      "Train Loss: 272890.1875 | Valid Loss: 298402.8750\n",
      "\n",
      "Epoch 482/800\n",
      "Train Loss: 229694.7344 | Valid Loss: 254195.5469\n",
      "\n",
      "Epoch 483/800\n",
      "Train Loss: 320041.6562 | Valid Loss: 346002.4375\n",
      "\n",
      "Epoch 484/800\n",
      "Train Loss: 316844.2812 | Valid Loss: 352284.0312\n",
      "\n",
      "Epoch 485/800\n",
      "Train Loss: 236971.4062 | Valid Loss: 262772.1562\n",
      "\n",
      "Epoch 486/800\n",
      "Train Loss: 143962.8281 | Valid Loss: 163349.8906\n",
      "\n",
      "Epoch 487/800\n",
      "Train Loss: 106776.6406 | Valid Loss: 125104.1094\n",
      "\n",
      "Epoch 488/800\n",
      "Train Loss: 106482.1875 | Valid Loss: 119383.6406\n",
      "\n",
      "Epoch 489/800\n",
      "Train Loss: 112182.4219 | Valid Loss: 125933.7031\n",
      "\n",
      "Epoch 490/800\n",
      "Train Loss: 106810.8750 | Valid Loss: 120640.7891\n",
      "\n",
      "Epoch 491/800\n",
      "Train Loss: 96573.0703 | Valid Loss: 108618.5312\n",
      "\n",
      "Epoch 492/800\n",
      "Train Loss: 79310.4609 | Valid Loss: 90989.4297\n",
      "\n",
      "Epoch 493/800\n",
      "Train Loss: 66742.0000 | Valid Loss: 80987.5938\n",
      "\n",
      "Epoch 494/800\n",
      "Train Loss: 62550.6172 | Valid Loss: 70315.3516\n",
      "\n",
      "Epoch 495/800\n",
      "Train Loss: 61291.2422 | Valid Loss: 68775.3594\n",
      "\n",
      "Epoch 496/800\n",
      "Train Loss: 61342.6211 | Valid Loss: 68625.5703\n",
      "\n",
      "Epoch 497/800\n",
      "Train Loss: 60711.7344 | Valid Loss: 67595.0156\n",
      "\n",
      "Epoch 498/800\n",
      "Train Loss: 55339.0078 | Valid Loss: 64276.1328\n",
      "\n",
      "Epoch 499/800\n",
      "Train Loss: 53495.5352 | Valid Loss: 59700.6641\n",
      "\n",
      "Epoch 500/800\n",
      "Train Loss: 49125.5742 | Valid Loss: 55393.4141\n",
      "\n",
      "Epoch 501/800\n",
      "Train Loss: 44922.9609 | Valid Loss: 52678.4883\n",
      "\n",
      "Epoch 502/800\n",
      "Train Loss: 43974.5781 | Valid Loss: 48269.4844\n",
      "\n",
      "Epoch 503/800\n",
      "Train Loss: 43871.6133 | Valid Loss: 47978.2148\n",
      "\n",
      "Epoch 504/800\n",
      "Train Loss: 39700.6562 | Valid Loss: 47878.4609\n",
      "\n",
      "Epoch 505/800\n",
      "Train Loss: 41786.3359 | Valid Loss: 44930.0391\n",
      "\n",
      "Epoch 506/800\n",
      "Train Loss: 38259.4336 | Valid Loss: 43149.7656\n",
      "\n",
      "Epoch 507/800\n",
      "Train Loss: 36167.1016 | Valid Loss: 41551.2227\n",
      "\n",
      "Epoch 508/800\n",
      "Train Loss: 35459.2422 | Valid Loss: 39236.0391\n",
      "\n",
      "Epoch 509/800\n",
      "Train Loss: 33338.1562 | Valid Loss: 37766.2461\n",
      "\n",
      "Epoch 510/800\n",
      "Train Loss: 32074.6016 | Valid Loss: 37244.4883\n",
      "\n",
      "Epoch 511/800\n",
      "Train Loss: 32043.2480 | Valid Loss: 34525.5273\n",
      "\n",
      "Epoch 512/800\n",
      "Train Loss: 32679.0137 | Valid Loss: 35784.5000\n",
      "\n",
      "Epoch 513/800\n",
      "Train Loss: 31508.4023 | Valid Loss: 34007.4375\n",
      "\n",
      "Epoch 514/800\n",
      "Train Loss: 29078.2773 | Valid Loss: 33169.9102\n",
      "\n",
      "Epoch 515/800\n",
      "Train Loss: 29693.2500 | Valid Loss: 31659.1543\n",
      "\n",
      "Epoch 516/800\n",
      "Train Loss: 28333.9316 | Valid Loss: 31543.0332\n",
      "\n",
      "Epoch 517/800\n",
      "Train Loss: 26888.2617 | Valid Loss: 31446.0762\n",
      "\n",
      "Epoch 518/800\n",
      "Train Loss: 28290.4883 | Valid Loss: 30194.9023\n",
      "\n",
      "Epoch 519/800\n",
      "Train Loss: 26791.7344 | Valid Loss: 29793.4648\n",
      "\n",
      "Epoch 520/800\n",
      "Train Loss: 27192.8379 | Valid Loss: 30070.2070\n",
      "\n",
      "Epoch 521/800\n",
      "Train Loss: 25737.6719 | Valid Loss: 28986.8672\n",
      "\n",
      "Epoch 522/800\n",
      "Train Loss: 24939.9922 | Valid Loss: 28961.1133\n",
      "\n",
      "Epoch 523/800\n",
      "Train Loss: 25175.3086 | Valid Loss: 28544.5879\n",
      "\n",
      "Epoch 524/800\n",
      "Train Loss: 24381.7441 | Valid Loss: 26330.4121\n",
      "\n",
      "Epoch 525/800\n",
      "Train Loss: 24083.9746 | Valid Loss: 27799.2246\n",
      "\n",
      "Epoch 526/800\n",
      "Train Loss: 23651.7188 | Valid Loss: 26408.1074\n",
      "\n",
      "Epoch 527/800\n",
      "Train Loss: 23570.6172 | Valid Loss: 26735.8613\n",
      "\n",
      "Epoch 528/800\n",
      "Train Loss: 23273.2676 | Valid Loss: 25109.5410\n",
      "\n",
      "Epoch 529/800\n",
      "Train Loss: 22605.7441 | Valid Loss: 26128.2969\n",
      "\n",
      "Epoch 530/800\n",
      "Train Loss: 23013.3926 | Valid Loss: 25951.5020\n",
      "\n",
      "Epoch 531/800\n",
      "Train Loss: 21983.6055 | Valid Loss: 25560.5176\n",
      "\n",
      "Epoch 532/800\n",
      "Train Loss: 22809.3184 | Valid Loss: 25115.5312\n",
      "\n",
      "Epoch 533/800\n",
      "Train Loss: 22053.1816 | Valid Loss: 24854.8730\n",
      "\n",
      "Epoch 534/800\n",
      "Train Loss: 21643.7949 | Valid Loss: 24009.7109\n",
      "\n",
      "Epoch 535/800\n",
      "Train Loss: 20817.9004 | Valid Loss: 23478.5820\n",
      "\n",
      "Epoch 536/800\n",
      "Train Loss: 20624.7266 | Valid Loss: 24038.3711\n",
      "\n",
      "Epoch 537/800\n",
      "Train Loss: 20481.1582 | Valid Loss: 23766.4629\n",
      "\n",
      "Epoch 538/800\n",
      "Train Loss: 20407.4336 | Valid Loss: 23162.1348\n",
      "\n",
      "Epoch 539/800\n",
      "Train Loss: 20453.0488 | Valid Loss: 22675.8262\n",
      "\n",
      "Epoch 540/800\n",
      "Train Loss: 20041.5410 | Valid Loss: 22359.8516\n",
      "\n",
      "Epoch 541/800\n",
      "Train Loss: 19688.8691 | Valid Loss: 21905.9160\n",
      "\n",
      "Epoch 542/800\n",
      "Train Loss: 19756.5059 | Valid Loss: 22049.7539\n",
      "\n",
      "Epoch 543/800\n",
      "Train Loss: 19217.6387 | Valid Loss: 22632.1797\n",
      "\n",
      "Epoch 544/800\n",
      "Train Loss: 19139.9023 | Valid Loss: 21450.9922\n",
      "\n",
      "Epoch 545/800\n",
      "Train Loss: 18735.1152 | Valid Loss: 21145.5234\n",
      "\n",
      "Epoch 546/800\n",
      "Train Loss: 18201.0977 | Valid Loss: 21083.2480\n",
      "\n",
      "Epoch 547/800\n",
      "Train Loss: 18830.3848 | Valid Loss: 21691.0859\n",
      "\n",
      "Epoch 548/800\n",
      "Train Loss: 17047.0332 | Valid Loss: 19978.6113\n",
      "\n",
      "Epoch 549/800\n",
      "Train Loss: 17877.9883 | Valid Loss: 20778.6465\n",
      "\n",
      "Epoch 550/800\n",
      "Train Loss: 17643.8887 | Valid Loss: 20638.7988\n",
      "\n",
      "Epoch 551/800\n",
      "Train Loss: 17579.1523 | Valid Loss: 20151.2578\n",
      "\n",
      "Epoch 552/800\n",
      "Train Loss: 16992.1250 | Valid Loss: 19390.1465\n",
      "\n",
      "Epoch 553/800\n",
      "Train Loss: 17634.2227 | Valid Loss: 20482.9844\n",
      "\n",
      "Epoch 554/800\n",
      "Train Loss: 17289.5723 | Valid Loss: 19113.6602\n",
      "\n",
      "Epoch 555/800\n",
      "Train Loss: 17242.6211 | Valid Loss: 18253.8359\n",
      "\n",
      "Epoch 556/800\n",
      "Train Loss: 17463.2520 | Valid Loss: 19111.4336\n",
      "\n",
      "Epoch 557/800\n",
      "Train Loss: 16880.3066 | Valid Loss: 18327.8105\n",
      "\n",
      "Epoch 558/800\n",
      "Train Loss: 16893.6387 | Valid Loss: 18609.3066\n",
      "\n",
      "Epoch 559/800\n",
      "Train Loss: 16332.4473 | Valid Loss: 18762.5117\n",
      "\n",
      "Epoch 560/800\n",
      "Train Loss: 15986.0557 | Valid Loss: 17717.5859\n",
      "\n",
      "Epoch 561/800\n",
      "Train Loss: 16350.6270 | Valid Loss: 17140.9824\n",
      "\n",
      "Epoch 562/800\n",
      "Train Loss: 16171.5840 | Valid Loss: 17319.6914\n",
      "\n",
      "Epoch 563/800\n",
      "Train Loss: 16344.9111 | Valid Loss: 17985.7051\n",
      "\n",
      "Epoch 564/800\n",
      "Train Loss: 15410.3447 | Valid Loss: 18283.3086\n",
      "\n",
      "Epoch 565/800\n",
      "Train Loss: 14820.2910 | Valid Loss: 17080.6914\n",
      "\n",
      "Epoch 566/800\n",
      "Train Loss: 14966.3809 | Valid Loss: 17413.0176\n",
      "\n",
      "Epoch 567/800\n",
      "Train Loss: 15878.1631 | Valid Loss: 17073.6797\n",
      "\n",
      "Epoch 568/800\n",
      "Train Loss: 14526.9336 | Valid Loss: 17027.5840\n",
      "\n",
      "Epoch 569/800\n",
      "Train Loss: 15277.7705 | Valid Loss: 17471.7539\n",
      "\n",
      "Epoch 570/800\n",
      "Train Loss: 14878.3838 | Valid Loss: 16208.5518\n",
      "\n",
      "Epoch 571/800\n",
      "Train Loss: 15073.4365 | Valid Loss: 16619.7773\n",
      "\n",
      "Epoch 572/800\n",
      "Train Loss: 14548.0986 | Valid Loss: 17266.6562\n",
      "\n",
      "Epoch 573/800\n",
      "Train Loss: 14562.6426 | Valid Loss: 16112.5596\n",
      "\n",
      "Epoch 574/800\n",
      "Train Loss: 14458.8477 | Valid Loss: 16463.5918\n",
      "\n",
      "Epoch 575/800\n",
      "Train Loss: 14171.2559 | Valid Loss: 15839.6826\n",
      "\n",
      "Epoch 576/800\n",
      "Train Loss: 14372.1064 | Valid Loss: 16319.9629\n",
      "\n",
      "Epoch 577/800\n",
      "Train Loss: 14203.9961 | Valid Loss: 15509.6602\n",
      "\n",
      "Epoch 578/800\n",
      "Train Loss: 13864.3584 | Valid Loss: 15010.7041\n",
      "\n",
      "Epoch 579/800\n",
      "Train Loss: 14142.7705 | Valid Loss: 15662.2520\n",
      "\n",
      "Epoch 580/800\n",
      "Train Loss: 13874.1465 | Valid Loss: 15478.7871\n",
      "\n",
      "Epoch 581/800\n",
      "Train Loss: 13694.5977 | Valid Loss: 15332.9150\n",
      "\n",
      "Epoch 582/800\n",
      "Train Loss: 13328.5693 | Valid Loss: 15267.6523\n",
      "\n",
      "Epoch 583/800\n",
      "Train Loss: 12998.0361 | Valid Loss: 15508.3965\n",
      "\n",
      "Epoch 584/800\n",
      "Train Loss: 13269.6074 | Valid Loss: 15083.0430\n",
      "\n",
      "Epoch 585/800\n",
      "Train Loss: 13425.4365 | Valid Loss: 14176.8447\n",
      "\n",
      "Epoch 586/800\n",
      "Train Loss: 13545.5674 | Valid Loss: 14275.9824\n",
      "\n",
      "Epoch 587/800\n",
      "Train Loss: 12709.2266 | Valid Loss: 14335.6953\n",
      "\n",
      "Epoch 588/800\n",
      "Train Loss: 12738.1797 | Valid Loss: 13578.6621\n",
      "\n",
      "Epoch 589/800\n",
      "Train Loss: 12747.5420 | Valid Loss: 14614.9951\n",
      "\n",
      "Epoch 590/800\n",
      "Train Loss: 12430.2451 | Valid Loss: 14151.1562\n",
      "\n",
      "Epoch 591/800\n",
      "Train Loss: 12470.4561 | Valid Loss: 13150.8574\n",
      "\n",
      "Epoch 592/800\n",
      "Train Loss: 12455.4150 | Valid Loss: 13722.8379\n",
      "\n",
      "Epoch 593/800\n",
      "Train Loss: 12334.5312 | Valid Loss: 13729.6777\n",
      "\n",
      "Epoch 594/800\n",
      "Train Loss: 12472.5674 | Valid Loss: 13156.7275\n",
      "\n",
      "Epoch 595/800\n",
      "Train Loss: 11887.5752 | Valid Loss: 13470.6816\n",
      "\n",
      "Epoch 596/800\n",
      "Train Loss: 12161.0322 | Valid Loss: 13527.6650\n",
      "\n",
      "Epoch 597/800\n",
      "Train Loss: 12090.9209 | Valid Loss: 13679.4561\n",
      "\n",
      "Epoch 598/800\n",
      "Train Loss: 11838.6914 | Valid Loss: 13319.8447\n",
      "\n",
      "Epoch 599/800\n",
      "Train Loss: 11836.7832 | Valid Loss: 13217.8330\n",
      "\n",
      "Epoch 600/800\n",
      "Train Loss: 11844.7783 | Valid Loss: 13214.6113\n",
      "\n",
      "Epoch 601/800\n",
      "Train Loss: 11571.7217 | Valid Loss: 12873.9170\n",
      "\n",
      "Epoch 602/800\n",
      "Train Loss: 11371.3838 | Valid Loss: 12760.0586\n",
      "\n",
      "Epoch 603/800\n",
      "Train Loss: 11427.9443 | Valid Loss: 12694.4043\n",
      "\n",
      "Epoch 604/800\n",
      "Train Loss: 11587.9502 | Valid Loss: 12513.3311\n",
      "\n",
      "Epoch 605/800\n",
      "Train Loss: 11309.8301 | Valid Loss: 12353.7568\n",
      "\n",
      "Epoch 606/800\n",
      "Train Loss: 11172.5635 | Valid Loss: 12325.3896\n",
      "\n",
      "Epoch 607/800\n",
      "Train Loss: 10990.3525 | Valid Loss: 12573.2188\n",
      "\n",
      "Epoch 608/800\n",
      "Train Loss: 10892.1533 | Valid Loss: 12346.2178\n",
      "\n",
      "Epoch 609/800\n",
      "Train Loss: 10890.7666 | Valid Loss: 12090.9209\n",
      "\n",
      "Epoch 610/800\n",
      "Train Loss: 10981.2393 | Valid Loss: 11601.2314\n",
      "\n",
      "Epoch 611/800\n",
      "Train Loss: 10733.7441 | Valid Loss: 12109.0283\n",
      "\n",
      "Epoch 612/800\n",
      "Train Loss: 10392.0049 | Valid Loss: 12036.7646\n",
      "\n",
      "Epoch 613/800\n",
      "Train Loss: 10761.3457 | Valid Loss: 11929.5576\n",
      "\n",
      "Epoch 614/800\n",
      "Train Loss: 10426.4609 | Valid Loss: 11760.7510\n",
      "\n",
      "Epoch 615/800\n",
      "Train Loss: 10594.1826 | Valid Loss: 11975.3896\n",
      "\n",
      "Epoch 616/800\n",
      "Train Loss: 9820.7266 | Valid Loss: 11804.0244\n",
      "\n",
      "Epoch 617/800\n",
      "Train Loss: 10208.7979 | Valid Loss: 11549.9004\n",
      "\n",
      "Epoch 618/800\n",
      "Train Loss: 10306.0586 | Valid Loss: 11213.9902\n",
      "\n",
      "Epoch 619/800\n",
      "Train Loss: 10349.7578 | Valid Loss: 11746.0713\n",
      "\n",
      "Epoch 620/800\n",
      "Train Loss: 9919.4082 | Valid Loss: 11034.4102\n",
      "\n",
      "Epoch 621/800\n",
      "Train Loss: 9888.6875 | Valid Loss: 11332.5977\n",
      "\n",
      "Epoch 622/800\n",
      "Train Loss: 9568.1650 | Valid Loss: 11045.7744\n",
      "\n",
      "Epoch 623/800\n",
      "Train Loss: 9953.4639 | Valid Loss: 10686.6172\n",
      "\n",
      "Epoch 624/800\n",
      "Train Loss: 9548.0010 | Valid Loss: 10867.4414\n",
      "\n",
      "Epoch 625/800\n",
      "Train Loss: 9690.4639 | Valid Loss: 10934.7217\n",
      "\n",
      "Epoch 626/800\n",
      "Train Loss: 9747.1025 | Valid Loss: 10637.7969\n",
      "\n",
      "Epoch 627/800\n",
      "Train Loss: 9859.7930 | Valid Loss: 10549.9648\n",
      "\n",
      "Epoch 628/800\n",
      "Train Loss: 9561.6396 | Valid Loss: 10564.1387\n",
      "\n",
      "Epoch 629/800\n",
      "Train Loss: 9365.8096 | Valid Loss: 10512.5195\n",
      "\n",
      "Epoch 630/800\n",
      "Train Loss: 9524.4033 | Valid Loss: 10524.4736\n",
      "\n",
      "Epoch 631/800\n",
      "Train Loss: 9302.6494 | Valid Loss: 10624.9082\n",
      "\n",
      "Epoch 632/800\n",
      "Train Loss: 9273.0273 | Valid Loss: 10277.0205\n",
      "\n",
      "Epoch 633/800\n",
      "Train Loss: 9029.9932 | Valid Loss: 10434.3965\n",
      "\n",
      "Epoch 634/800\n",
      "Train Loss: 8927.3809 | Valid Loss: 10163.8975\n",
      "\n",
      "Epoch 635/800\n",
      "Train Loss: 8965.4795 | Valid Loss: 10074.2178\n",
      "\n",
      "Epoch 636/800\n",
      "Train Loss: 9147.0195 | Valid Loss: 10139.7510\n",
      "\n",
      "Epoch 637/800\n",
      "Train Loss: 8894.9756 | Valid Loss: 10271.1787\n",
      "\n",
      "Epoch 638/800\n",
      "Train Loss: 8815.6992 | Valid Loss: 10369.9062\n",
      "\n",
      "Epoch 639/800\n",
      "Train Loss: 8882.5674 | Valid Loss: 10116.1709\n",
      "\n",
      "Epoch 640/800\n",
      "Train Loss: 8919.7217 | Valid Loss: 9988.5732\n",
      "\n",
      "Epoch 641/800\n",
      "Train Loss: 8703.3359 | Valid Loss: 9815.8330\n",
      "\n",
      "Epoch 642/800\n",
      "Train Loss: 8838.7070 | Valid Loss: 9786.9209\n",
      "\n",
      "Epoch 643/800\n",
      "Train Loss: 8756.0947 | Valid Loss: 9583.3994\n",
      "\n",
      "Epoch 644/800\n",
      "Train Loss: 8427.8906 | Valid Loss: 9351.7754\n",
      "\n",
      "Epoch 645/800\n",
      "Train Loss: 8488.6670 | Valid Loss: 9263.5898\n",
      "\n",
      "Epoch 646/800\n",
      "Train Loss: 8886.4121 | Valid Loss: 9429.2031\n",
      "\n",
      "Epoch 647/800\n",
      "Train Loss: 8501.7188 | Valid Loss: 9269.8438\n",
      "\n",
      "Epoch 648/800\n",
      "Train Loss: 8486.7773 | Valid Loss: 9269.2549\n",
      "\n",
      "Epoch 649/800\n",
      "Train Loss: 8274.2432 | Valid Loss: 9200.2109\n",
      "\n",
      "Epoch 650/800\n",
      "Train Loss: 8115.4248 | Valid Loss: 9308.8828\n",
      "\n",
      "Epoch 651/800\n",
      "Train Loss: 8258.4395 | Valid Loss: 9220.1631\n",
      "\n",
      "Epoch 652/800\n",
      "Train Loss: 8266.2490 | Valid Loss: 9253.5469\n",
      "\n",
      "Epoch 653/800\n",
      "Train Loss: 7901.9404 | Valid Loss: 8790.4609\n",
      "\n",
      "Epoch 654/800\n",
      "Train Loss: 8070.6045 | Valid Loss: 8946.3936\n",
      "\n",
      "Epoch 655/800\n",
      "Train Loss: 8352.0322 | Valid Loss: 8745.1768\n",
      "\n",
      "Epoch 656/800\n",
      "Train Loss: 7729.5605 | Valid Loss: 8953.9746\n",
      "\n",
      "Epoch 657/800\n",
      "Train Loss: 7967.8623 | Valid Loss: 8660.7998\n",
      "\n",
      "Epoch 658/800\n",
      "Train Loss: 7683.7461 | Valid Loss: 8912.8506\n",
      "\n",
      "Epoch 659/800\n",
      "Train Loss: 7687.5166 | Valid Loss: 8771.4287\n",
      "\n",
      "Epoch 660/800\n",
      "Train Loss: 7427.7861 | Valid Loss: 8841.1162\n",
      "\n",
      "Epoch 661/800\n",
      "Train Loss: 7733.4702 | Valid Loss: 8630.1494\n",
      "\n",
      "Epoch 662/800\n",
      "Train Loss: 7726.6860 | Valid Loss: 8755.9521\n",
      "\n",
      "Epoch 663/800\n",
      "Train Loss: 7691.1055 | Valid Loss: 8219.2139\n",
      "\n",
      "Epoch 664/800\n",
      "Train Loss: 7582.0190 | Valid Loss: 8656.6523\n",
      "\n",
      "Epoch 665/800\n",
      "Train Loss: 7594.4556 | Valid Loss: 8516.3232\n",
      "\n",
      "Epoch 666/800\n",
      "Train Loss: 7370.4351 | Valid Loss: 8156.5679\n",
      "\n",
      "Epoch 667/800\n",
      "Train Loss: 7466.3223 | Valid Loss: 8503.9072\n",
      "\n",
      "Epoch 668/800\n",
      "Train Loss: 7342.1948 | Valid Loss: 8030.3535\n",
      "\n",
      "Epoch 669/800\n",
      "Train Loss: 7454.2720 | Valid Loss: 8135.0908\n",
      "\n",
      "Epoch 670/800\n",
      "Train Loss: 7080.7949 | Valid Loss: 8289.6006\n",
      "\n",
      "Epoch 671/800\n",
      "Train Loss: 7158.9854 | Valid Loss: 8183.1860\n",
      "\n",
      "Epoch 672/800\n",
      "Train Loss: 7156.6729 | Valid Loss: 8138.5503\n",
      "\n",
      "Epoch 673/800\n",
      "Train Loss: 7228.2437 | Valid Loss: 7906.3936\n",
      "\n",
      "Epoch 674/800\n",
      "Train Loss: 6970.5933 | Valid Loss: 7946.5776\n",
      "\n",
      "Epoch 675/800\n",
      "Train Loss: 7009.1309 | Valid Loss: 7947.6592\n",
      "\n",
      "Epoch 676/800\n",
      "Train Loss: 6907.2192 | Valid Loss: 7919.8862\n",
      "\n",
      "Epoch 677/800\n",
      "Train Loss: 6882.2500 | Valid Loss: 7835.2573\n",
      "\n",
      "Epoch 678/800\n",
      "Train Loss: 6622.6084 | Valid Loss: 7881.8735\n",
      "\n",
      "Epoch 679/800\n",
      "Train Loss: 7085.5415 | Valid Loss: 7739.3296\n",
      "\n",
      "Epoch 680/800\n",
      "Train Loss: 7191.2480 | Valid Loss: 7963.0239\n",
      "\n",
      "Epoch 681/800\n",
      "Train Loss: 6911.4526 | Valid Loss: 7602.7676\n",
      "\n",
      "Epoch 682/800\n",
      "Train Loss: 6871.6548 | Valid Loss: 7800.8662\n",
      "\n",
      "Epoch 683/800\n",
      "Train Loss: 6613.7461 | Valid Loss: 7731.0669\n",
      "\n",
      "Epoch 684/800\n",
      "Train Loss: 6683.5498 | Valid Loss: 7314.6284\n",
      "\n",
      "Epoch 685/800\n",
      "Train Loss: 6807.9292 | Valid Loss: 7583.8989\n",
      "\n",
      "Epoch 686/800\n",
      "Train Loss: 6574.2734 | Valid Loss: 7446.4438\n",
      "\n",
      "Epoch 687/800\n",
      "Train Loss: 6600.3833 | Valid Loss: 7542.8013\n",
      "\n",
      "Epoch 688/800\n",
      "Train Loss: 6541.3032 | Valid Loss: 7252.2017\n",
      "\n",
      "Epoch 689/800\n",
      "Train Loss: 6550.2349 | Valid Loss: 7403.8364\n",
      "\n",
      "Epoch 690/800\n",
      "Train Loss: 6586.6304 | Valid Loss: 7343.2783\n",
      "\n",
      "Epoch 691/800\n",
      "Train Loss: 6287.1934 | Valid Loss: 7528.9341\n",
      "\n",
      "Epoch 692/800\n",
      "Train Loss: 6386.4736 | Valid Loss: 7386.8398\n",
      "\n",
      "Epoch 693/800\n",
      "Train Loss: 6320.2539 | Valid Loss: 7333.9727\n",
      "\n",
      "Epoch 694/800\n",
      "Train Loss: 6257.6670 | Valid Loss: 7255.2495\n",
      "\n",
      "Epoch 695/800\n",
      "Train Loss: 6580.9780 | Valid Loss: 7374.7559\n",
      "\n",
      "Epoch 696/800\n",
      "Train Loss: 6450.0415 | Valid Loss: 7096.5342\n",
      "\n",
      "Epoch 697/800\n",
      "Train Loss: 6140.9204 | Valid Loss: 7124.9756\n",
      "\n",
      "Epoch 698/800\n",
      "Train Loss: 6125.5054 | Valid Loss: 7053.9014\n",
      "\n",
      "Epoch 699/800\n",
      "Train Loss: 6344.4976 | Valid Loss: 6881.7695\n",
      "\n",
      "Epoch 700/800\n",
      "Train Loss: 6124.6196 | Valid Loss: 7214.2544\n",
      "\n",
      "Epoch 701/800\n",
      "Train Loss: 6213.1602 | Valid Loss: 6983.2344\n",
      "\n",
      "Epoch 702/800\n",
      "Train Loss: 6052.4648 | Valid Loss: 6845.5933\n",
      "\n",
      "Epoch 703/800\n",
      "Train Loss: 5927.1089 | Valid Loss: 6941.3276\n",
      "\n",
      "Epoch 704/800\n",
      "Train Loss: 6278.6582 | Valid Loss: 6870.3965\n",
      "\n",
      "Epoch 705/800\n",
      "Train Loss: 5776.1353 | Valid Loss: 6714.2695\n",
      "\n",
      "Epoch 706/800\n",
      "Train Loss: 6342.3799 | Valid Loss: 6661.0566\n",
      "\n",
      "Epoch 707/800\n",
      "Train Loss: 5908.2285 | Valid Loss: 6617.6694\n",
      "\n",
      "Epoch 708/800\n",
      "Train Loss: 6085.7500 | Valid Loss: 6616.0566\n",
      "\n",
      "Epoch 709/800\n",
      "Train Loss: 5901.8379 | Valid Loss: 6576.9238\n",
      "\n",
      "Epoch 710/800\n",
      "Train Loss: 5881.7051 | Valid Loss: 6681.7261\n",
      "\n",
      "Epoch 711/800\n",
      "Train Loss: 5814.8486 | Valid Loss: 6428.1089\n",
      "\n",
      "Epoch 712/800\n",
      "Train Loss: 5785.7026 | Valid Loss: 6395.6133\n",
      "\n",
      "Epoch 713/800\n",
      "Train Loss: 5800.0205 | Valid Loss: 6702.9146\n",
      "\n",
      "Epoch 714/800\n",
      "Train Loss: 5718.3389 | Valid Loss: 6686.1338\n",
      "\n",
      "Epoch 715/800\n",
      "Train Loss: 5881.6255 | Valid Loss: 6461.2236\n",
      "\n",
      "Epoch 716/800\n",
      "Train Loss: 5851.3374 | Valid Loss: 6358.1948\n",
      "\n",
      "Epoch 717/800\n",
      "Train Loss: 5892.6997 | Valid Loss: 6325.4287\n",
      "\n",
      "Epoch 718/800\n",
      "Train Loss: 5658.3774 | Valid Loss: 6444.3345\n",
      "\n",
      "Epoch 719/800\n",
      "Train Loss: 5709.0928 | Valid Loss: 6157.8652\n",
      "\n",
      "Epoch 720/800\n",
      "Train Loss: 5780.6733 | Valid Loss: 6389.4214\n",
      "\n",
      "Epoch 721/800\n",
      "Train Loss: 5484.5532 | Valid Loss: 6223.5156\n",
      "\n",
      "Epoch 722/800\n",
      "Train Loss: 5525.1855 | Valid Loss: 6275.7192\n",
      "\n",
      "Epoch 723/800\n",
      "Train Loss: 5508.8896 | Valid Loss: 6313.3911\n",
      "\n",
      "Epoch 724/800\n",
      "Train Loss: 5444.9067 | Valid Loss: 6310.4932\n",
      "\n",
      "Epoch 725/800\n",
      "Train Loss: 5753.7710 | Valid Loss: 6359.6289\n",
      "\n",
      "Epoch 726/800\n",
      "Train Loss: 5515.0342 | Valid Loss: 6021.7158\n",
      "\n",
      "Epoch 727/800\n",
      "Train Loss: 5267.7231 | Valid Loss: 5983.9849\n",
      "\n",
      "Epoch 728/800\n",
      "Train Loss: 5362.3960 | Valid Loss: 5984.3086\n",
      "\n",
      "Epoch 729/800\n",
      "Train Loss: 5334.2637 | Valid Loss: 5932.1768\n",
      "\n",
      "Epoch 730/800\n",
      "Train Loss: 5753.7969 | Valid Loss: 5834.4404\n",
      "\n",
      "Epoch 731/800\n",
      "Train Loss: 5393.5864 | Valid Loss: 6085.7900\n",
      "\n",
      "Epoch 732/800\n",
      "Train Loss: 5297.3188 | Valid Loss: 5853.1782\n",
      "\n",
      "Epoch 733/800\n",
      "Train Loss: 5341.7026 | Valid Loss: 5883.0239\n",
      "\n",
      "Epoch 734/800\n",
      "Train Loss: 5231.4199 | Valid Loss: 5761.0278\n",
      "\n",
      "Epoch 735/800\n",
      "Train Loss: 5253.1064 | Valid Loss: 5850.8140\n",
      "\n",
      "Epoch 736/800\n",
      "Train Loss: 5015.6035 | Valid Loss: 5901.1685\n",
      "\n",
      "Epoch 737/800\n",
      "Train Loss: 5161.5898 | Valid Loss: 5615.9648\n",
      "\n",
      "Epoch 738/800\n",
      "Train Loss: 5208.9976 | Valid Loss: 5701.0591\n",
      "\n",
      "Epoch 739/800\n",
      "Train Loss: 5160.1841 | Valid Loss: 5678.9463\n",
      "\n",
      "Epoch 740/800\n",
      "Train Loss: 5106.4360 | Valid Loss: 5819.5664\n",
      "\n",
      "Epoch 741/800\n",
      "Train Loss: 5109.5840 | Valid Loss: 5630.9702\n",
      "\n",
      "Epoch 742/800\n",
      "Train Loss: 5091.5991 | Valid Loss: 5813.5425\n",
      "\n",
      "Epoch 743/800\n",
      "Train Loss: 5134.5581 | Valid Loss: 5596.6372\n",
      "\n",
      "Epoch 744/800\n",
      "Train Loss: 4953.8286 | Valid Loss: 5741.9185\n",
      "\n",
      "Epoch 745/800\n",
      "Train Loss: 5057.6919 | Valid Loss: 5523.2856\n",
      "\n",
      "Epoch 746/800\n",
      "Train Loss: 5217.5488 | Valid Loss: 5682.4941\n",
      "\n",
      "Epoch 747/800\n",
      "Train Loss: 5036.8926 | Valid Loss: 5507.0664\n",
      "\n",
      "Epoch 748/800\n",
      "Train Loss: 5060.8320 | Valid Loss: 5672.3301\n",
      "\n",
      "Epoch 749/800\n",
      "Train Loss: 4705.8774 | Valid Loss: 5515.4248\n",
      "\n",
      "Epoch 750/800\n",
      "Train Loss: 4894.0708 | Valid Loss: 5357.3906\n",
      "\n",
      "Epoch 751/800\n",
      "Train Loss: 4737.4287 | Valid Loss: 5570.1367\n",
      "\n",
      "Epoch 752/800\n",
      "Train Loss: 4923.8799 | Valid Loss: 5415.0015\n",
      "\n",
      "Epoch 753/800\n",
      "Train Loss: 4923.4863 | Valid Loss: 5563.5732\n",
      "\n",
      "Epoch 754/800\n",
      "Train Loss: 4785.2017 | Valid Loss: 5446.9297\n",
      "\n",
      "Epoch 755/800\n",
      "Train Loss: 4839.4478 | Valid Loss: 5693.6382\n",
      "\n",
      "Epoch 756/800\n",
      "Train Loss: 4708.5063 | Valid Loss: 5257.0869\n",
      "\n",
      "Epoch 757/800\n",
      "Train Loss: 4759.3965 | Valid Loss: 5054.9736\n",
      "\n",
      "Epoch 758/800\n",
      "Train Loss: 4779.6982 | Valid Loss: 5369.1445\n",
      "\n",
      "Epoch 759/800\n",
      "Train Loss: 4722.3594 | Valid Loss: 5262.0254\n",
      "\n",
      "Epoch 760/800\n",
      "Train Loss: 4712.6865 | Valid Loss: 5348.5913\n",
      "\n",
      "Epoch 761/800\n",
      "Train Loss: 4648.3809 | Valid Loss: 5342.7437\n",
      "\n",
      "Epoch 762/800\n",
      "Train Loss: 4738.4888 | Valid Loss: 5163.1646\n",
      "\n",
      "Epoch 763/800\n",
      "Train Loss: 4560.4468 | Valid Loss: 5425.6772\n",
      "\n",
      "Epoch 764/800\n",
      "Train Loss: 4609.9297 | Valid Loss: 5233.0732\n",
      "\n",
      "Epoch 765/800\n",
      "Train Loss: 4496.7632 | Valid Loss: 5044.1982\n",
      "\n",
      "Epoch 766/800\n",
      "Train Loss: 4617.9873 | Valid Loss: 5025.5933\n",
      "\n",
      "Epoch 767/800\n",
      "Train Loss: 4586.3516 | Valid Loss: 5098.2437\n",
      "\n",
      "Epoch 768/800\n",
      "Train Loss: 4676.2046 | Valid Loss: 4916.4229\n",
      "\n",
      "Epoch 769/800\n",
      "Train Loss: 4536.8188 | Valid Loss: 5066.3965\n",
      "\n",
      "Epoch 770/800\n",
      "Train Loss: 4443.2061 | Valid Loss: 5050.9062\n",
      "\n",
      "Epoch 771/800\n",
      "Train Loss: 4437.7974 | Valid Loss: 5183.2759\n",
      "\n",
      "Epoch 772/800\n",
      "Train Loss: 4517.9951 | Valid Loss: 5006.9028\n",
      "\n",
      "Epoch 773/800\n",
      "Train Loss: 4328.3335 | Valid Loss: 5051.4897\n",
      "\n",
      "Epoch 774/800\n",
      "Train Loss: 4462.7231 | Valid Loss: 4836.6553\n",
      "\n",
      "Epoch 775/800\n",
      "Train Loss: 4528.5415 | Valid Loss: 4918.6680\n",
      "\n",
      "Epoch 776/800\n",
      "Train Loss: 4480.8394 | Valid Loss: 5028.6406\n",
      "\n",
      "Epoch 777/800\n",
      "Train Loss: 4281.9556 | Valid Loss: 4573.4448\n",
      "\n",
      "Epoch 778/800\n",
      "Train Loss: 4353.6958 | Valid Loss: 4757.1509\n",
      "\n",
      "Epoch 779/800\n",
      "Train Loss: 4490.9727 | Valid Loss: 5022.7432\n",
      "\n",
      "Epoch 780/800\n",
      "Train Loss: 4418.6377 | Valid Loss: 4801.5068\n",
      "\n",
      "Epoch 781/800\n",
      "Train Loss: 4239.3345 | Valid Loss: 4713.1382\n",
      "\n",
      "Epoch 782/800\n",
      "Train Loss: 4259.5303 | Valid Loss: 4934.1519\n",
      "\n",
      "Epoch 783/800\n",
      "Train Loss: 4104.2334 | Valid Loss: 4871.2852\n",
      "\n",
      "Epoch 784/800\n",
      "Train Loss: 4314.7793 | Valid Loss: 4872.6265\n",
      "\n",
      "Epoch 785/800\n",
      "Train Loss: 4242.8242 | Valid Loss: 4797.8853\n",
      "\n",
      "Epoch 786/800\n",
      "Train Loss: 4277.0303 | Valid Loss: 4708.9238\n",
      "\n",
      "Epoch 787/800\n",
      "Train Loss: 4207.5405 | Valid Loss: 4641.1001\n",
      "\n",
      "Epoch 788/800\n",
      "Train Loss: 4204.0864 | Valid Loss: 4571.4097\n",
      "\n",
      "Epoch 789/800\n",
      "Train Loss: 4044.6143 | Valid Loss: 4880.7666\n",
      "\n",
      "Epoch 790/800\n",
      "Train Loss: 4027.4724 | Valid Loss: 4467.1455\n",
      "\n",
      "Epoch 791/800\n",
      "Train Loss: 4147.7397 | Valid Loss: 4690.5444\n",
      "\n",
      "Epoch 792/800\n",
      "Train Loss: 4137.3691 | Valid Loss: 4694.6357\n",
      "\n",
      "Epoch 793/800\n",
      "Train Loss: 3951.8616 | Valid Loss: 4755.5918\n",
      "\n",
      "Epoch 794/800\n",
      "Train Loss: 3969.9436 | Valid Loss: 4652.6421\n",
      "\n",
      "Epoch 795/800\n",
      "Train Loss: 4149.9585 | Valid Loss: 4598.2173\n",
      "\n",
      "Epoch 796/800\n",
      "Train Loss: 4097.5654 | Valid Loss: 4496.0718\n",
      "\n",
      "Epoch 797/800\n",
      "Train Loss: 4011.6711 | Valid Loss: 4544.7988\n",
      "\n",
      "Epoch 798/800\n",
      "Train Loss: 4062.4683 | Valid Loss: 4395.7793\n",
      "\n",
      "Epoch 799/800\n",
      "Train Loss: 3927.4744 | Valid Loss: 4526.2344\n",
      "\n",
      "Epoch 800/800\n",
      "Train Loss: 4075.8806 | Valid Loss: 4451.3823\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "model = TransformerRegressor(emb_dim=768, hidden_dim=256).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr = 5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=lr,        # 学习率的最小值 (min_lr)\n",
    "    max_lr=5e-4,       # 学习率的最大值 (max_lr)\n",
    "    step_size_up=8, # 学习率从 min_lr 上升到 max_lr 所需的迭代次数\n",
    "    mode='exp_range',   # 调度模式：'triangular' (三角波)\n",
    "    gamma=0.95,\n",
    "    cycle_momentum=False # 如果使用带有动量的优化器 (如 Adam)，通常设置为 False\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 4️⃣ 训练 + 早停\n",
    "# =========================\n",
    "EPOCsmiles = 400\n",
    "best_val_loss = float('inf')\n",
    "save_path = 'best_model.pth'\n",
    "patience = 10\n",
    "counter = 0\n",
    "best_loss=np.inf\n",
    "\n",
    "\n",
    "for epoch in range(EPOCsmiles):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCsmiles}\")\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    X, Y, smiles, H = X.to(device), Y.to(device), smiles.to(device), H.to(device)\n",
    "\n",
    "    pred = model(X, smiles, H)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    loss_train = criterion(pred[:5000],Y[:5000])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_valid = criterion(pred[5000:],Y[5000:])\n",
    "\n",
    "\n",
    "    print(f\"Train Loss: {loss_train:.4f} | Valid Loss: {loss_valid:.4f}\")\n",
    "\n",
    "    if loss_valid < best_loss:\n",
    "        best_loss = loss_valid\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        print(f\"⭐ Saved best model at epoch {epoch+1}, val loss = {best_loss:.4f}\")\n",
    "    scheduler.step()\n",
    "# for epoch in range(EPOCsmiles):\n",
    "#     print(f\"\\nEpoch {epoch+1}/{EPOCsmiles}\")\n",
    "#     loss = 0\n",
    "#     for i in range(1):\n",
    "        \n",
    "#         model.train()\n",
    "#         s = i*5000\n",
    "#         e = (i+1)*5000\n",
    "#         X_train, Y_train, smiles_train, H_train = X[s:e].to(device), Y[s:e].to(device), smiles[s:e].to(device), H[s:e].to(device)\n",
    "    \n",
    "#         pred = model(X_train, smiles_train, H_train)\n",
    "    \n",
    "#         optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "#         loss_train = criterion(pred,Y_train)\n",
    "#         loss_train.backward()\n",
    "#         optimizer.step()\n",
    "#         loss += loss_train\n",
    "        \n",
    "#     avg_train_loss = loss/5\n",
    "#     print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "#     model.eval()\n",
    "#     X_test, Y_test, smiles_test, H_test = X[5000:].to(device), Y[5000:].to(device), smiles[5000:].to(device), H[5000:].to(device)\n",
    "#     pred = model(X_test, smiles_test, H_test)\n",
    "#     loss_valid = criterion(pred,Y_test)\n",
    "\n",
    "#     if loss_valid < best_loss:\n",
    "#         best_loss = loss_valid\n",
    "#         torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "#         print(f\"⭐ Saved best model at epoch {epoch+1}, val loss = {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cc189297-72cf-408f-a6aa-d6eb73dd5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,) (5000,)\n",
      "\n",
      "=====  Performance =====\n",
      "RMSE   : 0.5681\n",
      "MAE    : 0.5142\n",
      "R2     : -0.1731\n",
      "Spearman: 0.2894\n",
      "Pearson : 0.3032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "model.load_state_dict(torch.load(save_path))  # 加载最佳模型\n",
    "model.eval()\n",
    "\n",
    "# forward 只跑一次\n",
    "preds = model(X, smiles, H).cpu().detach().numpy().flatten()[5000:]\n",
    "trues = Y.cpu().detach().numpy().flatten()[5000:]\n",
    "\n",
    "# preds = model(X[5000:], smiles[5000:], H[5000:]).cpu().detach().numpy().flatten()\n",
    "# trues = Y.cpu().detach().numpy().flatten()[5000:]\n",
    "\n",
    "\n",
    "# preds = model(X_test, smiles_test, H_test).cpu().detach().numpy().flatten()\n",
    "# trues = Y_test.cpu().detach().numpy().flatten()\n",
    "\n",
    "print(preds.shape, trues.shape)\n",
    "rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "mae  = mean_absolute_error(trues, preds)\n",
    "r2   = r2_score(trues, preds)\n",
    "rho_s, _ = stats.spearmanr(trues, preds)\n",
    "rho_p, _ = stats.pearsonr(trues, preds)\n",
    "\n",
    "print(f\"\\n=====  Performance =====\")\n",
    "print(f\"RMSE   : {rmse:.4f}\")\n",
    "print(f\"MAE    : {mae:.4f}\")\n",
    "print(f\"R2     : {r2:.4f}\")\n",
    "print(f\"Spearman: {rho_s:.4f}\")\n",
    "print(f\"Pearson : {rho_p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "374a37d4-fdf0-4387-85b1-77e74c3e04e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2438216462.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m=====  Performance =====\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "=====  Performance =====\n",
    "RMSE   : 0.4032\n",
    "MAE    : 0.3307\n",
    "R2     : 0.4092\n",
    "Spearman: 0.6486\n",
    "Pearson : 0.6718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a18e08-8054-4e39-bf86-7a02a9fee90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-isim]",
   "language": "python",
   "name": "conda-env-.conda-isim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
